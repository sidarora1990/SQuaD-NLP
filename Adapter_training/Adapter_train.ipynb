{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Nh2zllxPJh",
        "outputId": "b791ea3a-b125-452a-cbfc-369abbe7b4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adapter-transformers\n",
            "  Downloading adapter_transformers-3.2.1-py3-none-any.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from adapter-transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from adapter-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, xxhash, dill, multiprocess, huggingface-hub, adapter-transformers, datasets\n",
            "Successfully installed adapter-transformers-3.2.1 datasets-2.13.1 dill-0.3.6 huggingface-hub-0.15.1 multiprocess-0.70.14 tokenizers-0.13.3 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U adapter-transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFtPypEXf7DL",
        "outputId": "efa61faa-1885-4789-f2a1-102dd86577e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.28k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a506f550bc74737b45dc8a15c63cd9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aab03edb0254ee798bf85c8393225d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.02k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a27648a20b04667818c6cbfbed8c47d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset squad_v2/squad_v2 to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e54ba5de25a446faae4837482ee68a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/9.55M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d81399c07dd42b49341b510f5fcadab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf2f6412f8d248c98981b8590c8455a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77c981223e494920becc8a3388cc7738"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51fb5ead0c224623b81c728b157274f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e88b1f3c1614ecb99d1783344c2cb85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset squad_v2 downloaded and prepared to /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecc5e19f244c4173840094cc93dd0891"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "raw_datasets = load_dataset('squad_v2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KpSUnDLhOAir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6raFTFXegIoU"
      },
      "outputs": [],
      "source": [
        "do_train = True # False\n",
        "do_eval = True\n",
        "\n",
        "# epochs, bs, GA\n",
        "evaluation_strategy = \"epoch\" # no\n",
        "\n",
        "# fp16\n",
        "fp16_opt_level = 'O1'\n",
        "fp16_backend = \"auto\"\n",
        "fp16_full_eval = False\n",
        "\n",
        "# optimizer (AdamW)\n",
        "weight_decay = 0.01 # 0.0\n",
        "adam_beta1 = 0.9\n",
        "adam_beta2 = 0.999\n",
        "\n",
        "# scheduler\n",
        "lr_scheduler_type = 'linear'\n",
        "warmup_ratio = 0.0\n",
        "warmup_steps = 0\n",
        "\n",
        "# logs\n",
        "logging_strategy = \"steps\"\n",
        "logging_first_step = True # False\n",
        "logging_steps = 500     # if strategy = \"steps\"\n",
        "eval_steps = logging_steps # logging_steps\n",
        "\n",
        "# checkpoints\n",
        "save_strategy = \"epoch\" # steps\n",
        "save_steps = 500 # if save_strategy = \"steps\"\n",
        "save_total_limit = 1 # None\n",
        "\n",
        "# no cuda, seed\n",
        "no_cuda = False\n",
        "seed = 42\n",
        "\n",
        "# bar\n",
        "disable_tqdm = False # True\n",
        "remove_unused_columns = True\n",
        "path_to_outputs = \"./outputs\"\n",
        "\n",
        "# subfolder for model outputs\n",
        "output_dir = path_to_outputs + '/output_dir'\n",
        "overwrite_output_dir = True # False\n",
        "\n",
        "# logs\n",
        "logging_dir = path_to_outputs + '/logging_dir'\n",
        "batch_size = 16\n",
        "gradient_accumulation_steps = 1\n",
        "\n",
        "learning_rate = 1e-4\n",
        "num_train_epochs = 3\n",
        "\n",
        "adam_epsilon = 1e-7\n",
        "\n",
        "fp16 = True\n",
        "\n",
        "# best model\n",
        "load_best_model_at_end = True\n",
        "metric_for_best_model = \"loss\"\n",
        "greater_is_better = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-sFBB92ChM2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f91b525-9bf5-42f9-c894-39e828cddf6a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa3446592776403cb7747819c8475c61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3aca3b8c4eee481a9d40b578da044320"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbedc062a2444bec9cb7652d0d14964c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faea679eb3464ab29d90f8568e2a7701"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NpNwmhqAhX-3"
      },
      "outputs": [],
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-jpCb-ZqhYuW"
      },
      "outputs": [],
      "source": [
        "def prepare_train_features(examples):\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "324vZJNYhrKv",
        "outputId": "48340a3c-89fb-4f44-a6ee-311117a4fd29"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/130319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36faf554afe041b4a0aba6460d5c3194"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11873 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16716b8e0d34472db807797860847de4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pad_on_right = tokenizer.padding_side == \"right\"\n",
        "tokenized_datasets = raw_datasets.map(prepare_train_features, batched=True, remove_columns=raw_datasets[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxz8fTg_lWNQ",
        "outputId": "3217c8c7-1367-46f8-f441-f218ab750c6d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50e1ca07860045bd852f6be254a4a5af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "orig_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHO5TPgJLEM4",
        "outputId": "a0b8d564-a42d-4b20-da6d-852240c42124"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124056578"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mFSACmXiAmL",
        "outputId": "52f6128d-072f-4e47-e3c3-1373aa92b461"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-anli_r3', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='6e70446e07ca3e36fdfd3d3764f0e6b657a14e78'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-art', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='d9c8ecbd38bb3591f5ff81fb788a16ea69887ddb'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-boolq', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='5b6612537722d176bf335a4c0d04a69eb842d50e'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-cola', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='6d43f29f44bebff381f7df59ccf9da1bb8887b76'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-commonsense_qa', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='03dfd99f5c5b4540df91429e9ce26c19584c3353'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-comqa', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='a8664332fd39968fb3c5a51e27c1c8870a6246e9'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-conll2000', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='da8d31e93f6a4644e89cb27da2cfa35b29985ce8'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-conll2003', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='e9517bce9d5227eed13a721b99116e5dcf4f3f53'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-conll2003_pos', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='2029a8b505f41e5bb735fbaa2f6761308d3d784a'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-copa', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='a2dcb370e920baaa555baa8c2c0385af7492edb8'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-cosmos_qa', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='254fd7d6efe54a93e487fb03b7ad05c2e659765d'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-cq', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='068e8cd423bc4a5336b510177165f4aaf3c9fdaa'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-drop', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='341fea5e77ef2123708d85914ba2da4ebac128fa'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-duorc_p', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='5061b421c6f50bcc771eee6c49ce2a16feb350ed'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-duorc_s', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='5b1104976a5a353832c457dc8ef120d047e233bf'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-emo', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='1a75d223481a3ab0c46816b96b608f9811232a0a'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-emotion', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='5f0af6e1e7c814a4e4bb54930acf4c110fda3236'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-fce_error_detection', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='c03fdd67c3276cc67bc40c06dc9f4ad7497dc4fa'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-hellaswag', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='d1b9638af1003f8e758c5af5bc276fcbe07b4144'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-hotpotqa', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='ab258d7f37531b9f6da58d6feac2ddecda85a702'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-imdb', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='76cc0d13be06fb59771919caca43082b3afaab2e'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-mit_movie_trivia', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='2873cf0fa02c45cf9cdc61fcd57e638795b5b0ad'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-mnli', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='bcf0e23b79a0b307c36c450d4ec3d3d1d2b3697d'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-mrpc', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='93f025fbdadcd07a71a1c896c1781bfd3b38554b'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-multirc', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='83ee3f3c852c88c2acb403c10a68b7152622fd69'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-newsqa', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='e5dd792b830ee49c6a90479422aad8dc2a08728c'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-pmb_sem_tagging', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='b8fa80b01246d65851cafa1b0422d449f0dd9957'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-qnli', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='c9727b05da53c810310c48ce0da071b914dd2023'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-qqp', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='c9422ce22026c655ef6fec3ecef72cf15f80aa78'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-quail', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='01ad0c29d7d61fffe42c4b3ba75143d54e847289'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-quartz', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='68fbd9b6d5f61af975571890ef20a224b08de968'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-quoref', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='b8b0696e0c02c21b4170c8aa435f7c74a000b1d8'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-race', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='b581ae58e8e690b8b673a1b1c60b977e2aada51e'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-record', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='a2cda5d7ec2f9fbcc9f845967551def7772048f9'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-rotten_tomatoes', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='a072887e68f079a68d36d3669b855b8211b1a015'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-rte', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='024a5657934a91fd4aabb1f2f1854b57d28c39b6'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-scicite', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='533ae729810c6165844e37850e329be124dce2b5'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-scitail', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='3ae8796ee9558b91c371617a66c4522b96185938'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-sick', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='c57c4fa23a1adf26805dbc1e00716d8ce14c9415'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-snli', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='325f78dfb7ab5df658141ec842205819e7cd2777'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-social_i_qa', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='d69cb6383390cfe69643a466401f9254bca9c4c9'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-squad', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='f1507c5b9c07db12729b02f481ffb0ab434c042f'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-squad_v2', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='0d5a6614b68ffcd1c2d068ee4e7878ed69ead076'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-sst2', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='12640a8432219a3014565addb69d71935938fa8c'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-stsb', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='15bae7ed95ec63b716f6687b1df163e3af499363'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-swag', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='2ba0e9a0b89d6c2a92405bb469fee3af78fa4d76'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-trec', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='7b69de3b363c03923b2c9d719b49938929cec0b6'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-ud_deprel', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='627dc7d7c89eca1a2000ad42fa1c6bff0917f4c9'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-ud_en_ewt', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='1624f5737b5dec1f694d009a870b6267a28c9751'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-ud_pos', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='92061930503b4a8712f81ec954c1406509522d4c'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-wic', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='c7f1f014d504e709b248d88e751b1e142ccf038f'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-wikihop', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='26473fe7b7c4ab74c9b708ac2577e3edf6398335'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-winogrande', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='5474f3b92d0b8d1c938cecd708c1343d30619ee7'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-wnut_17', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='b6f6ebcaa977fb45c49d25bbb0830a949e6028d3'),\n",
              " AdapterInfo(source='hf', adapter_id='AdapterHub/roberta-base-pf-yelp_polarity', model_name='roberta-base', task=None, subtask=None, username='AdapterHub', adapter_config=None, sha1_checksum='cf0605f6972d18d802d8abe16bf5f5d6e89c6bc1'),\n",
              " AdapterInfo(source='hf', adapter_id='SALT-NLP/pfadapter-roberta-base-rte-combined-value', model_name='roberta-base', task=None, subtask=None, username='SALT-NLP', adapter_config=None, sha1_checksum='1bc0b534969a335da8e1c979b8d52735b40ca26f'),\n",
              " AdapterInfo(source='hf', adapter_id='SALT-NLP/pfadapter-roberta-base-cola-combined-value', model_name='roberta-base', task=None, subtask=None, username='SALT-NLP', adapter_config=None, sha1_checksum='14f7125bf039c386a8caf41ee27a2aeae2561576'),\n",
              " AdapterInfo(source='hf', adapter_id='SALT-NLP/pfadapter-roberta-base-qnli-combined-value', model_name='roberta-base', task=None, subtask=None, username='SALT-NLP', adapter_config=None, sha1_checksum='9e86fe72f3da8fb0693d72b336893410b66ee355'),\n",
              " AdapterInfo(source='hf', adapter_id='SALT-NLP/pfadapter-roberta-base-sst2-combined-value', model_name='roberta-base', task=None, subtask=None, username='SALT-NLP', adapter_config=None, sha1_checksum='61796b10914754826ca6b1356864cb450f8c7d85'),\n",
              " AdapterInfo(source='hf', adapter_id='SALT-NLP/pfadapter-roberta-base-stsb-combined-value', model_name='roberta-base', task=None, subtask=None, username='SALT-NLP', adapter_config=None, sha1_checksum='53829f27784f45488d380bc9f6a4d79282ba871c'),\n",
              " AdapterInfo(source='hf', adapter_id='SALT-NLP/pfadapter-roberta-base-mnli-combined-value', model_name='roberta-base', task=None, subtask=None, username='SALT-NLP', adapter_config=None, sha1_checksum='6651a7789a30b10070437bfbb5f4b7b823794efd'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-rte', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='4a4b3fe9ce9d1cd37165155db51de2847a3f71b1'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-cola', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='4bfb622615cd0e87218740ec68cdf4b26e033fd7'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-qnli', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='ae6a010889c142e8bdd732649d1f6b741c7db711'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-sst2', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='a27eef1c9a04eef3170623440fe45e391439f7f4'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-stsb', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='d5a7c8dae37e52e1b6db88cb5a648bb816e65bbd'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-mnli', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='97bbfd9eb0a26f291b4ccd3c9b38598bd03ac5cd'),\n",
              " AdapterInfo(source='hf', adapter_id='SALT-NLP/pfadapter-roberta-base-qqp-combined-value', model_name='roberta-base', task=None, subtask=None, username='SALT-NLP', adapter_config=None, sha1_checksum='80e62e30bf51e3bc72faffb346e0346e18b37457'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-qqp', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='3b6aeae612cb9572c95e0dcd5bfabbb284cad492'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-value', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='7618b85bf5f202a135d56923785df22682739245'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-value-small', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='6302372ca58a27df6e5476e1663e0d8c84deac03'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-value-5k', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='8847b9176f3e30a58037baea7f8792910f2928de'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-value-10k', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='2946e1e539c4875b9ebababd8839d6097772cb15'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-value-eraser', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='11f2d22c0108b05f6f656e3a830d5c1071914bd1'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='4eb162287bf46ecf8e4a26068ffe1987fc1ca47f'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-adv', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='b7e73312ade8cb6b7e21daa5d21db9a0e44c0544'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-adv-aave', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='232d6c04f9b1bbd3f085b7cc7d6daafa71b41802'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-adv-IndianEnglish', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='d339a4deae959d1e31c1dd154035191604b93315'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-adv-ChicanoEnglish', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='e338959301ba08cbb6679b89a5a6533962d16c7c'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-adv-NigerianEnglish', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='376b37aa70221ff3597159015c575bc5d9c07f92'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-adv-CollSgE', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='c302b9a6197cbba4e8cc9b73d44e13f47a4cc339'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-adv-aave-contrast', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='3cf9b5a9cf0222d71b6f7ca5587490ff8a86d16f'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-adv-aave-adv-only', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='9b660ffe079f16bcb15c0f346fcb1569b850ea38'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/SQuAD_Adapter_RoBERTa', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='7775f92ef691cd1f23cfeee289cca28a377b77e9'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/HotpotQA_Adapter_RoBERTa', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='9f7c290e635a5ae80c5333510f5379bf17b805a5'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/NaturalQuestions_Adapter_RoBERTa', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='bf8ca5f5ae3ee04e3529afd203e6a4373c69bb6d'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/NewsQA_Adapter_RoBERTa', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='f5248982c88d0944b666c883de062d233a569557'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/SearchQA_Adapter_RoBERTa', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='c8cffba031cae0964cf2de1c5df664adc127681d'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/TriviaQA_Adapter_RoBERTa', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='b88b8f2fa910c5b512b8da6c188a75370c9749d7'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/MADE_HotpotQA_Adapter', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='7f1500cd50ed85d844d4e4dc19b6742394189640'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/MADE_NaturalQuestions_Adapter', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='1ac17c2370f54b5f10983af2da3967c03d6ae340'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/MADE_NewsQA_Adapter', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='8101d6d647caa1b3dd8c504bc834dad2cbde2848'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/MADE_SearchQA_Adapter', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='8c383430e608b9aef93c1ed2603a6fc1563c8e24'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/MADE_SQuAD_Adapter', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='1560d96e8f9cf341c0076178bbd9b72f9c1389cf'),\n",
              " AdapterInfo(source='hf', adapter_id='UKP-SQuARE/MADE_TriviaQA_Adapter', model_name='roberta-base', task=None, subtask=None, username='UKP-SQuARE', adapter_config=None, sha1_checksum='d78ab252055eb16b69b2b83d405280a04e32ae2e'),\n",
              " AdapterInfo(source='hf', adapter_id='WillHeld/pfadapter-roberta-base-tada-ot', model_name='roberta-base', task=None, subtask=None, username='WillHeld', adapter_config=None, sha1_checksum='7ec537f490521f1046c8e5c9f4b6d2669efb2de9')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from transformers import list_adapters\n",
        "\n",
        "adapter_infos = list_adapters(source=\"hf\", model_name=\"roberta-base\")\n",
        "adapter_infos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx_x965lmE0Z",
        "outputId": "2dfadbab-1fdb-41a3-ef72-2d1ec3bfbf04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta.embeddings.word_embeddings.weight\n",
            "roberta.embeddings.position_embeddings.weight\n",
            "roberta.embeddings.token_type_embeddings.weight\n",
            "roberta.embeddings.LayerNorm.weight\n",
            "roberta.embeddings.LayerNorm.bias\n",
            "roberta.encoder.layer.0.attention.self.query.weight\n",
            "roberta.encoder.layer.0.attention.self.query.bias\n",
            "roberta.encoder.layer.0.attention.self.key.weight\n",
            "roberta.encoder.layer.0.attention.self.key.bias\n",
            "roberta.encoder.layer.0.attention.self.value.weight\n",
            "roberta.encoder.layer.0.attention.self.value.bias\n",
            "roberta.encoder.layer.0.attention.output.dense.weight\n",
            "roberta.encoder.layer.0.attention.output.dense.bias\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.0.intermediate.dense.weight\n",
            "roberta.encoder.layer.0.intermediate.dense.bias\n",
            "roberta.encoder.layer.0.output.dense.weight\n",
            "roberta.encoder.layer.0.output.dense.bias\n",
            "roberta.encoder.layer.0.output.LayerNorm.weight\n",
            "roberta.encoder.layer.0.output.LayerNorm.bias\n",
            "roberta.encoder.layer.1.attention.self.query.weight\n",
            "roberta.encoder.layer.1.attention.self.query.bias\n",
            "roberta.encoder.layer.1.attention.self.key.weight\n",
            "roberta.encoder.layer.1.attention.self.key.bias\n",
            "roberta.encoder.layer.1.attention.self.value.weight\n",
            "roberta.encoder.layer.1.attention.self.value.bias\n",
            "roberta.encoder.layer.1.attention.output.dense.weight\n",
            "roberta.encoder.layer.1.attention.output.dense.bias\n",
            "roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.1.intermediate.dense.weight\n",
            "roberta.encoder.layer.1.intermediate.dense.bias\n",
            "roberta.encoder.layer.1.output.dense.weight\n",
            "roberta.encoder.layer.1.output.dense.bias\n",
            "roberta.encoder.layer.1.output.LayerNorm.weight\n",
            "roberta.encoder.layer.1.output.LayerNorm.bias\n",
            "roberta.encoder.layer.2.attention.self.query.weight\n",
            "roberta.encoder.layer.2.attention.self.query.bias\n",
            "roberta.encoder.layer.2.attention.self.key.weight\n",
            "roberta.encoder.layer.2.attention.self.key.bias\n",
            "roberta.encoder.layer.2.attention.self.value.weight\n",
            "roberta.encoder.layer.2.attention.self.value.bias\n",
            "roberta.encoder.layer.2.attention.output.dense.weight\n",
            "roberta.encoder.layer.2.attention.output.dense.bias\n",
            "roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.2.intermediate.dense.weight\n",
            "roberta.encoder.layer.2.intermediate.dense.bias\n",
            "roberta.encoder.layer.2.output.dense.weight\n",
            "roberta.encoder.layer.2.output.dense.bias\n",
            "roberta.encoder.layer.2.output.LayerNorm.weight\n",
            "roberta.encoder.layer.2.output.LayerNorm.bias\n",
            "roberta.encoder.layer.3.attention.self.query.weight\n",
            "roberta.encoder.layer.3.attention.self.query.bias\n",
            "roberta.encoder.layer.3.attention.self.key.weight\n",
            "roberta.encoder.layer.3.attention.self.key.bias\n",
            "roberta.encoder.layer.3.attention.self.value.weight\n",
            "roberta.encoder.layer.3.attention.self.value.bias\n",
            "roberta.encoder.layer.3.attention.output.dense.weight\n",
            "roberta.encoder.layer.3.attention.output.dense.bias\n",
            "roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.3.intermediate.dense.weight\n",
            "roberta.encoder.layer.3.intermediate.dense.bias\n",
            "roberta.encoder.layer.3.output.dense.weight\n",
            "roberta.encoder.layer.3.output.dense.bias\n",
            "roberta.encoder.layer.3.output.LayerNorm.weight\n",
            "roberta.encoder.layer.3.output.LayerNorm.bias\n",
            "roberta.encoder.layer.4.attention.self.query.weight\n",
            "roberta.encoder.layer.4.attention.self.query.bias\n",
            "roberta.encoder.layer.4.attention.self.key.weight\n",
            "roberta.encoder.layer.4.attention.self.key.bias\n",
            "roberta.encoder.layer.4.attention.self.value.weight\n",
            "roberta.encoder.layer.4.attention.self.value.bias\n",
            "roberta.encoder.layer.4.attention.output.dense.weight\n",
            "roberta.encoder.layer.4.attention.output.dense.bias\n",
            "roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.4.intermediate.dense.weight\n",
            "roberta.encoder.layer.4.intermediate.dense.bias\n",
            "roberta.encoder.layer.4.output.dense.weight\n",
            "roberta.encoder.layer.4.output.dense.bias\n",
            "roberta.encoder.layer.4.output.LayerNorm.weight\n",
            "roberta.encoder.layer.4.output.LayerNorm.bias\n",
            "roberta.encoder.layer.5.attention.self.query.weight\n",
            "roberta.encoder.layer.5.attention.self.query.bias\n",
            "roberta.encoder.layer.5.attention.self.key.weight\n",
            "roberta.encoder.layer.5.attention.self.key.bias\n",
            "roberta.encoder.layer.5.attention.self.value.weight\n",
            "roberta.encoder.layer.5.attention.self.value.bias\n",
            "roberta.encoder.layer.5.attention.output.dense.weight\n",
            "roberta.encoder.layer.5.attention.output.dense.bias\n",
            "roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.5.intermediate.dense.weight\n",
            "roberta.encoder.layer.5.intermediate.dense.bias\n",
            "roberta.encoder.layer.5.output.dense.weight\n",
            "roberta.encoder.layer.5.output.dense.bias\n",
            "roberta.encoder.layer.5.output.LayerNorm.weight\n",
            "roberta.encoder.layer.5.output.LayerNorm.bias\n",
            "roberta.encoder.layer.6.attention.self.query.weight\n",
            "roberta.encoder.layer.6.attention.self.query.bias\n",
            "roberta.encoder.layer.6.attention.self.key.weight\n",
            "roberta.encoder.layer.6.attention.self.key.bias\n",
            "roberta.encoder.layer.6.attention.self.value.weight\n",
            "roberta.encoder.layer.6.attention.self.value.bias\n",
            "roberta.encoder.layer.6.attention.output.dense.weight\n",
            "roberta.encoder.layer.6.attention.output.dense.bias\n",
            "roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.6.intermediate.dense.weight\n",
            "roberta.encoder.layer.6.intermediate.dense.bias\n",
            "roberta.encoder.layer.6.output.dense.weight\n",
            "roberta.encoder.layer.6.output.dense.bias\n",
            "roberta.encoder.layer.6.output.LayerNorm.weight\n",
            "roberta.encoder.layer.6.output.LayerNorm.bias\n",
            "roberta.encoder.layer.7.attention.self.query.weight\n",
            "roberta.encoder.layer.7.attention.self.query.bias\n",
            "roberta.encoder.layer.7.attention.self.key.weight\n",
            "roberta.encoder.layer.7.attention.self.key.bias\n",
            "roberta.encoder.layer.7.attention.self.value.weight\n",
            "roberta.encoder.layer.7.attention.self.value.bias\n",
            "roberta.encoder.layer.7.attention.output.dense.weight\n",
            "roberta.encoder.layer.7.attention.output.dense.bias\n",
            "roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.7.intermediate.dense.weight\n",
            "roberta.encoder.layer.7.intermediate.dense.bias\n",
            "roberta.encoder.layer.7.output.dense.weight\n",
            "roberta.encoder.layer.7.output.dense.bias\n",
            "roberta.encoder.layer.7.output.LayerNorm.weight\n",
            "roberta.encoder.layer.7.output.LayerNorm.bias\n",
            "roberta.encoder.layer.8.attention.self.query.weight\n",
            "roberta.encoder.layer.8.attention.self.query.bias\n",
            "roberta.encoder.layer.8.attention.self.key.weight\n",
            "roberta.encoder.layer.8.attention.self.key.bias\n",
            "roberta.encoder.layer.8.attention.self.value.weight\n",
            "roberta.encoder.layer.8.attention.self.value.bias\n",
            "roberta.encoder.layer.8.attention.output.dense.weight\n",
            "roberta.encoder.layer.8.attention.output.dense.bias\n",
            "roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.8.intermediate.dense.weight\n",
            "roberta.encoder.layer.8.intermediate.dense.bias\n",
            "roberta.encoder.layer.8.output.dense.weight\n",
            "roberta.encoder.layer.8.output.dense.bias\n",
            "roberta.encoder.layer.8.output.LayerNorm.weight\n",
            "roberta.encoder.layer.8.output.LayerNorm.bias\n",
            "roberta.encoder.layer.9.attention.self.query.weight\n",
            "roberta.encoder.layer.9.attention.self.query.bias\n",
            "roberta.encoder.layer.9.attention.self.key.weight\n",
            "roberta.encoder.layer.9.attention.self.key.bias\n",
            "roberta.encoder.layer.9.attention.self.value.weight\n",
            "roberta.encoder.layer.9.attention.self.value.bias\n",
            "roberta.encoder.layer.9.attention.output.dense.weight\n",
            "roberta.encoder.layer.9.attention.output.dense.bias\n",
            "roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.9.intermediate.dense.weight\n",
            "roberta.encoder.layer.9.intermediate.dense.bias\n",
            "roberta.encoder.layer.9.output.dense.weight\n",
            "roberta.encoder.layer.9.output.dense.bias\n",
            "roberta.encoder.layer.9.output.LayerNorm.weight\n",
            "roberta.encoder.layer.9.output.LayerNorm.bias\n",
            "roberta.encoder.layer.10.attention.self.query.weight\n",
            "roberta.encoder.layer.10.attention.self.query.bias\n",
            "roberta.encoder.layer.10.attention.self.key.weight\n",
            "roberta.encoder.layer.10.attention.self.key.bias\n",
            "roberta.encoder.layer.10.attention.self.value.weight\n",
            "roberta.encoder.layer.10.attention.self.value.bias\n",
            "roberta.encoder.layer.10.attention.output.dense.weight\n",
            "roberta.encoder.layer.10.attention.output.dense.bias\n",
            "roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.10.intermediate.dense.weight\n",
            "roberta.encoder.layer.10.intermediate.dense.bias\n",
            "roberta.encoder.layer.10.output.dense.weight\n",
            "roberta.encoder.layer.10.output.dense.bias\n",
            "roberta.encoder.layer.10.output.LayerNorm.weight\n",
            "roberta.encoder.layer.10.output.LayerNorm.bias\n",
            "roberta.encoder.layer.11.attention.self.query.weight\n",
            "roberta.encoder.layer.11.attention.self.query.bias\n",
            "roberta.encoder.layer.11.attention.self.key.weight\n",
            "roberta.encoder.layer.11.attention.self.key.bias\n",
            "roberta.encoder.layer.11.attention.self.value.weight\n",
            "roberta.encoder.layer.11.attention.self.value.bias\n",
            "roberta.encoder.layer.11.attention.output.dense.weight\n",
            "roberta.encoder.layer.11.attention.output.dense.bias\n",
            "roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "roberta.encoder.layer.11.intermediate.dense.weight\n",
            "roberta.encoder.layer.11.intermediate.dense.bias\n",
            "roberta.encoder.layer.11.output.dense.weight\n",
            "roberta.encoder.layer.11.output.dense.bias\n",
            "roberta.encoder.layer.11.output.LayerNorm.weight\n",
            "roberta.encoder.layer.11.output.LayerNorm.bias\n",
            "qa_outputs.weight\n",
            "qa_outputs.bias\n"
          ]
        }
      ],
      "source": [
        "for name, p in model.named_parameters():\n",
        "  if p.requires_grad == True:\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiwhKUjMhu6Z",
        "outputId": "a9d8111f-95c0-4a2b-9957-5c4c9cb8ad68"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9359b439ca9341919ceffee6a752cc1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)2ae2e/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1940cc4dfbdf41beb01a5399d17e5666"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/adapter_config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d3549ff7a72458797fc4e0fb690e847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)a04e32ae2e/README.md:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95a84c869cdd4c41819efeb72e3e5eda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)e2e/head_config.json:   0%|          | 0.00/262 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d745252801de4f6fb4f9fbdb472e5dc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model_head.bin:   0%|          | 0.00/7.25k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03f69f3ca579426085039701f794e618"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_adapter.bin:   0%|          | 0.00/7.19M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76850c97aea0439a9c9ef85e8cb8049f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "adapter_name = model.load_adapter(\"UKP-SQuARE/MADE_TriviaQA_Adapter\", source=\"hf\")\n",
        "model.set_active_adapters = adapter_name\n",
        "model.train_adapter([\"TriviaQA\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "new_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN3HL9KDNfBS",
        "outputId": "87af2cd9-d06e-4e34-df72-3115fe7418a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1790594"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJjPnbj7mL7l",
        "outputId": "c73ab3da-860c-49e6-b327-d7d9d7228641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta.encoder.layer.0.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.0.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.0.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.0.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.0.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.0.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.0.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.0.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.1.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.1.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.1.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.1.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.1.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.1.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.1.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.1.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.2.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.2.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.2.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.2.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.2.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.2.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.2.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.2.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.3.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.3.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.3.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.3.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.3.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.3.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.3.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.3.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.4.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.4.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.4.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.4.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.4.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.4.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.4.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.4.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.5.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.5.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.5.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.5.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.5.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.5.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.5.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.5.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.6.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.6.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.6.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.6.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.6.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.6.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.6.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.6.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.7.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.7.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.7.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.7.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.7.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.7.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.7.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.7.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.8.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.8.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.8.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.8.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.8.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.8.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.8.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.8.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.9.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.9.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.9.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.9.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.9.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.9.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.9.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.9.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.10.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.10.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.10.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.10.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.10.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.10.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.10.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.10.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.11.attention.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.11.attention.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.11.attention.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.11.attention.output.adapters.TriviaQA.adapter_up.bias\n",
            "roberta.encoder.layer.11.output.adapters.TriviaQA.adapter_down.0.weight\n",
            "roberta.encoder.layer.11.output.adapters.TriviaQA.adapter_down.0.bias\n",
            "roberta.encoder.layer.11.output.adapters.TriviaQA.adapter_up.weight\n",
            "roberta.encoder.layer.11.output.adapters.TriviaQA.adapter_up.bias\n",
            "qa_outputs.weight\n",
            "qa_outputs.bias\n"
          ]
        }
      ],
      "source": [
        "for name, p in model.named_parameters():\n",
        "  if p.requires_grad == True:\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in0Z6ozVmXnn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import TrainingArguments, AdapterTrainer, EvalPrediction\n",
        "#from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "from datasets import load_metric\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        overwrite_output_dir=overwrite_output_dir,\n",
        "        do_train=do_train,\n",
        "        do_eval=do_eval,\n",
        "        evaluation_strategy=evaluation_strategy,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        adam_beta1=adam_beta1,\n",
        "        adam_beta2=adam_beta2,\n",
        "        adam_epsilon=adam_epsilon,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        lr_scheduler_type=lr_scheduler_type,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        warmup_steps=warmup_steps,\n",
        "        logging_dir=logging_dir,         # directory for storing logs\n",
        "        logging_strategy=evaluation_strategy,\n",
        "        logging_steps=logging_steps,     # if strategy = \"steps\"\n",
        "        save_strategy=evaluation_strategy,          # model checkpoint saving strategy\n",
        "        save_steps=logging_steps,        # if strategy = \"steps\"\n",
        "        save_total_limit=save_total_limit,\n",
        "        fp16=fp16,\n",
        "        eval_steps=logging_steps,        # if strategy = \"steps\"\n",
        "        load_best_model_at_end=load_best_model_at_end,\n",
        "        metric_for_best_model=metric_for_best_model,\n",
        "        greater_is_better=greater_is_better\n",
        "        )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yEOMNyrme--",
        "outputId": "8ae1c0bb-5598-48cf-b4fe-e5fd8f2ab101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "from transformers.trainer_callback import EarlyStoppingCallback\n",
        "from transformers import default_data_collator\n",
        "\n",
        "data_collator = default_data_collator\n",
        "train_adapter=True\n",
        "#do_save_full_model=train_adapter, # save full model as we finetuned head + embeddings\n",
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PhNbQsCnmvtH",
        "outputId": "90a94aba-9296-4913-9d2d-170a548e5c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 131823\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 24717\n",
            "  Number of trainable parameters = 1790594\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24717' max='24717' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24717/24717 2:24:19, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.386100</td>\n",
              "      <td>0.930999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.987200</td>\n",
              "      <td>0.877207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.902000</td>\n",
              "      <td>0.863160</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 12165\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./outputs/output_dir/checkpoint-8239\n",
            "Configuration saved in ./outputs/output_dir/checkpoint-8239/TriviaQA/adapter_config.json\n",
            "Module weights saved in ./outputs/output_dir/checkpoint-8239/TriviaQA/pytorch_adapter.bin\n",
            "Configuration saved in ./outputs/output_dir/checkpoint-8239/TriviaQA/head_config.json\n",
            "Module weights saved in ./outputs/output_dir/checkpoint-8239/TriviaQA/pytorch_model_head.bin\n",
            "tokenizer config file saved in ./outputs/output_dir/checkpoint-8239/tokenizer_config.json\n",
            "Special tokens file saved in ./outputs/output_dir/checkpoint-8239/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 12165\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./outputs/output_dir/checkpoint-16478\n",
            "Configuration saved in ./outputs/output_dir/checkpoint-16478/TriviaQA/adapter_config.json\n",
            "Module weights saved in ./outputs/output_dir/checkpoint-16478/TriviaQA/pytorch_adapter.bin\n",
            "Configuration saved in ./outputs/output_dir/checkpoint-16478/TriviaQA/head_config.json\n",
            "Module weights saved in ./outputs/output_dir/checkpoint-16478/TriviaQA/pytorch_model_head.bin\n",
            "tokenizer config file saved in ./outputs/output_dir/checkpoint-16478/tokenizer_config.json\n",
            "Special tokens file saved in ./outputs/output_dir/checkpoint-16478/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 12165\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./outputs/output_dir/checkpoint-24717\n",
            "Configuration saved in ./outputs/output_dir/checkpoint-24717/TriviaQA/adapter_config.json\n",
            "Module weights saved in ./outputs/output_dir/checkpoint-24717/TriviaQA/pytorch_adapter.bin\n",
            "Configuration saved in ./outputs/output_dir/checkpoint-24717/TriviaQA/head_config.json\n",
            "Module weights saved in ./outputs/output_dir/checkpoint-24717/TriviaQA/pytorch_model_head.bin\n",
            "tokenizer config file saved in ./outputs/output_dir/checkpoint-24717/tokenizer_config.json\n",
            "Special tokens file saved in ./outputs/output_dir/checkpoint-24717/special_tokens_map.json\n",
            "Deleting older checkpoint [outputs/output_dir/checkpoint-8239] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best adapter(s) from ./outputs/output_dir/checkpoint-24717 (score: 0.8631603717803955).\n",
            "Loading module configuration from ./outputs/output_dir/checkpoint-24717/TriviaQA/adapter_config.json\n",
            "Overwriting existing adapter 'TriviaQA'.\n",
            "Loading module weights from ./outputs/output_dir/checkpoint-24717/TriviaQA/pytorch_adapter.bin\n",
            "Loading module configuration from ./outputs/output_dir/checkpoint-24717/TriviaQA/head_config.json\n",
            "Loading module weights from ./outputs/output_dir/checkpoint-24717/TriviaQA/pytorch_model_head.bin\n",
            "Deleting older checkpoint [outputs/output_dir/checkpoint-16478] due to args.save_total_limit\n",
            "Deleting older checkpoint [outputs/output_dir/checkpoint-24717] due to args.save_total_limit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=24717, training_loss=1.0917436356113708, metrics={'train_runtime': 8662.1286, 'train_samples_per_second': 45.655, 'train_steps_per_second': 2.853, 'total_flos': 7.913119261267814e+16, 'train_loss': 1.0917436356113708, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ3MyM-tm3xf"
      },
      "outputs": [],
      "source": [
        "def prepare_validation_features(examples):\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1 if pad_on_right else 0\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_features = raw_datasets[\"validation\"].map(\n",
        "    prepare_validation_features,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"validation\"].column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "37ad24ccd3404055a2aa9680aaec7d85",
            "dfcf0b5299f54b7893bdb28a0ca09f5f",
            "02b0714eaca545eaae1a1264d422a822",
            "1ff3463e181a43019d5433ab609b7f5a",
            "4b07a01c786547c19e309db234d59516",
            "627af73e0f304dc082412cb3609db220",
            "cd1aac65b10145d284a8ae5a38009496",
            "21ed73ca082c42d6a0f6e7231aa4dfdf",
            "190ddbf781ab45eb9ff1202ef2079ac6",
            "f9fac466697147499c59128f69b57a6c",
            "c9bc3c5633624886a3e90870039e05b7"
          ]
        },
        "id": "DYKnJCHJvAlq",
        "outputId": "2b742b90-cc16-4d85-bbb2-fc5fde89aecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11873 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37ad24ccd3404055a2aa9680aaec7d85"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_predictions = trainer.predict(validation_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "E3ufhbqnvgxI",
        "outputId": "0b6a72d0-8e6f-438a-ae48-e818f28ae405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 12165\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
      ],
      "metadata": {
        "id": "shFKcpDtvkQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_answer_length = 30"
      ],
      "metadata": {
        "id": "CwQknn_yvpLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import collections\n",
        "\n",
        "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
        "    all_start_logits, all_end_logits = raw_predictions\n",
        "    # Build a map example to its corresponding features.\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    # The dictionaries we have to fill.\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    # Logging.\n",
        "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
        "\n",
        "    # Let's loop over all the examples!\n",
        "    for example_index, example in enumerate(tqdm(examples)):\n",
        "        # Those are the indices of the features associated to the current example.\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        min_null_score = None # Only used if squad_v2 is True.\n",
        "        valid_answers = []\n",
        "\n",
        "        context = example[\"context\"]\n",
        "        # Looping through all the features associated to the current example.\n",
        "        for feature_index in feature_indices:\n",
        "            # We grab the predictions of the model for this feature.\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
        "            # context.\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            # Update minimum null prediction.\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\n",
        "                min_null_score = feature_null_score\n",
        "\n",
        "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                    # to part of the input_ids that are not in the context.\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "\n",
        "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
        "        #if not squad_v2:\n",
        "        #    predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "        #else:\n",
        "        answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
        "        predictions[example[\"id\"]] = answer\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "hqrzyx3Hvx_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = postprocess_qa_predictions(raw_datasets[\"validation\"], validation_features, raw_predictions.predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "531763b715fa4a1c8c9b1a8b5ac45844",
            "886b517889f543218fb0d2582fb697ad",
            "6b814d48adb94145b08f9b4ce7fbb5ee",
            "34cc278cf1724da883008b40c187c45d",
            "1d51f72cd00647de91f889b05f40a463",
            "7fead96b9a214a838c638c45b7e227df",
            "4de54c67cd494b4b9fcdc02ad5ed120f",
            "bdf83e9ce65440d19cab95dea15cce3d",
            "ace19ead5a3540bba9f28299a1c21cfe",
            "7959631b5dc54860a63bb4e2ac22463a",
            "71d2351c7e9a46f992fdd675f75525bb"
          ]
        },
        "id": "vzH3fwpcv9sb",
        "outputId": "0552920f-1cb3-411a-e910-b3ef757bff81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Post-processing 11873 example predictions split into 12165 features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11873 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "531763b715fa4a1c8c9b1a8b5ac45844"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"squad_v2\")\n",
        "formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
        "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in raw_datasets[\"validation\"]]\n",
        "metric.compute(predictions=formatted_predictions, references=references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "afd3c5076b8f4a6f8b81b8f45f0fa289",
            "c0ead68d8c5e46bfa2371793ac32ad5c",
            "d699aadcd01746f990b84efb8432fd43",
            "d6da2899ec7a4a1d9a2c1111a62cf2f1",
            "910c4628fa7c40d1bb822890e9facc0d",
            "8a7f8dfa74b14cf7baa93ffde4a45eb5",
            "394450f4e8ac44e5bfb58c21d681aea7",
            "61cce1af9c9040cd9d9e524b99681275",
            "b16e79663c464cab914dd24885255c85",
            "a5b5943017b7460a97004d28e355e652",
            "942e54896f024ede93857775bfcff2bb",
            "41877fa7c18b4f72be9d179db0130f23",
            "f6c475b910794dbf978f2bec5058eb47",
            "d63826438a42465193a614226c53a340",
            "d27fd7e4699640afb8c636286cc9703e",
            "083eb09c7679488da57408db05923d1d",
            "8f3c003ac6c04ba285a6b8e2c16b5667",
            "cce5761053ba4b85b4674f0c0ddb62ed",
            "e5ddff1608e84c8a82dcf9369344cae8",
            "f820cb7b7fc54cf0856e5c4f3b435efd",
            "0a679fae42d0452b95e4d11a68d0b5e4",
            "e66cf11b21dd432687db977121e56a78"
          ]
        },
        "id": "dDulR1CCwBc7",
        "outputId": "9c72092d-2aa0-49a1-e9d5-29757a6f8469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-00ad96c514da>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"squad_v2\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.25k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afd3c5076b8f4a6f8b81b8f45f0fa289"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/3.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41877fa7c18b4f72be9d179db0130f23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact': 77.84890086751453,\n",
              " 'f1': 80.8957059608256,\n",
              " 'total': 11873,\n",
              " 'HasAns_exact': 75.57354925775978,\n",
              " 'HasAns_f1': 81.67589690838109,\n",
              " 'HasAns_total': 5928,\n",
              " 'NoAns_exact': 80.11774600504626,\n",
              " 'NoAns_f1': 80.11774600504626,\n",
              " 'NoAns_total': 5945,\n",
              " 'best_exact': 77.84890086751453,\n",
              " 'best_exact_thresh': 0.0,\n",
              " 'best_f1': 80.89570596082547,\n",
              " 'best_f1_thresh': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_adapter(\"./outputs/adapter_output\", \"TriviaQA\")\n",
        "trainer.model.save_adapter(\"./outputs/output_dir\", adapter_name=\"TriviaQA\", with_head=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVcU3Ny3N2MO",
        "outputId": "ab5435ae-2d57-4c0d-b51f-5bb0cfedc9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in ./outputs/output_dir/adapter_config.json\n",
            "Module weights saved in ./outputs/output_dir/pytorch_adapter.bin\n",
            "Configuration saved in ./outputs/output_dir/head_config.json\n",
            "Module weights saved in ./outputs/output_dir/pytorch_model_head.bin\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37ad24ccd3404055a2aa9680aaec7d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfcf0b5299f54b7893bdb28a0ca09f5f",
              "IPY_MODEL_02b0714eaca545eaae1a1264d422a822",
              "IPY_MODEL_1ff3463e181a43019d5433ab609b7f5a"
            ],
            "layout": "IPY_MODEL_4b07a01c786547c19e309db234d59516"
          }
        },
        "dfcf0b5299f54b7893bdb28a0ca09f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_627af73e0f304dc082412cb3609db220",
            "placeholder": "​",
            "style": "IPY_MODEL_cd1aac65b10145d284a8ae5a38009496",
            "value": "Map: 100%"
          }
        },
        "02b0714eaca545eaae1a1264d422a822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21ed73ca082c42d6a0f6e7231aa4dfdf",
            "max": 11873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_190ddbf781ab45eb9ff1202ef2079ac6",
            "value": 11873
          }
        },
        "1ff3463e181a43019d5433ab609b7f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9fac466697147499c59128f69b57a6c",
            "placeholder": "​",
            "style": "IPY_MODEL_c9bc3c5633624886a3e90870039e05b7",
            "value": " 11873/11873 [00:23&lt;00:00, 635.41 examples/s]"
          }
        },
        "4b07a01c786547c19e309db234d59516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "627af73e0f304dc082412cb3609db220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1aac65b10145d284a8ae5a38009496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21ed73ca082c42d6a0f6e7231aa4dfdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "190ddbf781ab45eb9ff1202ef2079ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9fac466697147499c59128f69b57a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9bc3c5633624886a3e90870039e05b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "531763b715fa4a1c8c9b1a8b5ac45844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_886b517889f543218fb0d2582fb697ad",
              "IPY_MODEL_6b814d48adb94145b08f9b4ce7fbb5ee",
              "IPY_MODEL_34cc278cf1724da883008b40c187c45d"
            ],
            "layout": "IPY_MODEL_1d51f72cd00647de91f889b05f40a463"
          }
        },
        "886b517889f543218fb0d2582fb697ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fead96b9a214a838c638c45b7e227df",
            "placeholder": "​",
            "style": "IPY_MODEL_4de54c67cd494b4b9fcdc02ad5ed120f",
            "value": "100%"
          }
        },
        "6b814d48adb94145b08f9b4ce7fbb5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf83e9ce65440d19cab95dea15cce3d",
            "max": 11873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ace19ead5a3540bba9f28299a1c21cfe",
            "value": 11873
          }
        },
        "34cc278cf1724da883008b40c187c45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7959631b5dc54860a63bb4e2ac22463a",
            "placeholder": "​",
            "style": "IPY_MODEL_71d2351c7e9a46f992fdd675f75525bb",
            "value": " 11873/11873 [00:54&lt;00:00, 393.56it/s]"
          }
        },
        "1d51f72cd00647de91f889b05f40a463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fead96b9a214a838c638c45b7e227df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4de54c67cd494b4b9fcdc02ad5ed120f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdf83e9ce65440d19cab95dea15cce3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ace19ead5a3540bba9f28299a1c21cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7959631b5dc54860a63bb4e2ac22463a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d2351c7e9a46f992fdd675f75525bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afd3c5076b8f4a6f8b81b8f45f0fa289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0ead68d8c5e46bfa2371793ac32ad5c",
              "IPY_MODEL_d699aadcd01746f990b84efb8432fd43",
              "IPY_MODEL_d6da2899ec7a4a1d9a2c1111a62cf2f1"
            ],
            "layout": "IPY_MODEL_910c4628fa7c40d1bb822890e9facc0d"
          }
        },
        "c0ead68d8c5e46bfa2371793ac32ad5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a7f8dfa74b14cf7baa93ffde4a45eb5",
            "placeholder": "​",
            "style": "IPY_MODEL_394450f4e8ac44e5bfb58c21d681aea7",
            "value": "Downloading builder script: "
          }
        },
        "d699aadcd01746f990b84efb8432fd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61cce1af9c9040cd9d9e524b99681275",
            "max": 2253,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b16e79663c464cab914dd24885255c85",
            "value": 2253
          }
        },
        "d6da2899ec7a4a1d9a2c1111a62cf2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5b5943017b7460a97004d28e355e652",
            "placeholder": "​",
            "style": "IPY_MODEL_942e54896f024ede93857775bfcff2bb",
            "value": " 6.46k/? [00:00&lt;00:00, 145kB/s]"
          }
        },
        "910c4628fa7c40d1bb822890e9facc0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a7f8dfa74b14cf7baa93ffde4a45eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394450f4e8ac44e5bfb58c21d681aea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61cce1af9c9040cd9d9e524b99681275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b16e79663c464cab914dd24885255c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5b5943017b7460a97004d28e355e652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942e54896f024ede93857775bfcff2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41877fa7c18b4f72be9d179db0130f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6c475b910794dbf978f2bec5058eb47",
              "IPY_MODEL_d63826438a42465193a614226c53a340",
              "IPY_MODEL_d27fd7e4699640afb8c636286cc9703e"
            ],
            "layout": "IPY_MODEL_083eb09c7679488da57408db05923d1d"
          }
        },
        "f6c475b910794dbf978f2bec5058eb47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f3c003ac6c04ba285a6b8e2c16b5667",
            "placeholder": "​",
            "style": "IPY_MODEL_cce5761053ba4b85b4674f0c0ddb62ed",
            "value": "Downloading extra modules: "
          }
        },
        "d63826438a42465193a614226c53a340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ddff1608e84c8a82dcf9369344cae8",
            "max": 3188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f820cb7b7fc54cf0856e5c4f3b435efd",
            "value": 3188
          }
        },
        "d27fd7e4699640afb8c636286cc9703e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a679fae42d0452b95e4d11a68d0b5e4",
            "placeholder": "​",
            "style": "IPY_MODEL_e66cf11b21dd432687db977121e56a78",
            "value": " 11.3k/? [00:00&lt;00:00, 310kB/s]"
          }
        },
        "083eb09c7679488da57408db05923d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3c003ac6c04ba285a6b8e2c16b5667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cce5761053ba4b85b4674f0c0ddb62ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5ddff1608e84c8a82dcf9369344cae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f820cb7b7fc54cf0856e5c4f3b435efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a679fae42d0452b95e4d11a68d0b5e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e66cf11b21dd432687db977121e56a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}