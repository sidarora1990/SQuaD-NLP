{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEw69hRkeL9S"
   },
   "source": [
    "### Fine-tuning roberta large on Squad dataset for question-answering using adapter-lora concept -Hemant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCuwzR8HihOY",
    "outputId": "20695c6f-e6d4-47fb-a037-187566ad02b4"
   },
   "outputs": [],
   "source": [
    "# !pip install -U adapter-transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HJ04ipQ3-kmV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarath/anaconda3/envs/dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, AdapterTrainer, EvalPrediction, AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YdPQBSE7nmQU"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "raw_datasets = load_dataset('squad_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDKXvVoCizhO",
    "outputId": "bd6381a2-e94d-4cad-a53b-0b882a0a6c0f"
   },
   "outputs": [],
   "source": [
    "!mkdir outputs\n",
    "!mkdir saved_model\n",
    "!mkdir outputs/output_dir\n",
    "!mkdir outputs/logging_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xACyNsDYi1EO"
   },
   "outputs": [],
   "source": [
    "do_train = True # False\n",
    "do_eval = True\n",
    "\n",
    "# epochs, bs, GA\n",
    "evaluation_strategy = \"epoch\" # no\n",
    "\n",
    "# fp16\n",
    "fp16_opt_level = 'O1'\n",
    "fp16_backend = \"auto\"\n",
    "fp16_full_eval = False\n",
    "\n",
    "# optimizer (AdamW)\n",
    "weight_decay = 0.01 # 0.0\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "\n",
    "# scheduler\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.0\n",
    "warmup_steps = 0\n",
    "\n",
    "# logs\n",
    "logging_strategy = \"steps\"\n",
    "logging_first_step = True # False\n",
    "logging_steps = 500     # if strategy = \"steps\"\n",
    "eval_steps = logging_steps # logging_steps\n",
    "\n",
    "# checkpoints\n",
    "save_strategy = \"epoch\" # steps\n",
    "save_steps = 1000 # if save_strategy = \"steps\"\n",
    "save_total_limit = 1 # None\n",
    "\n",
    "# no cuda, seed\n",
    "no_cuda = False\n",
    "seed = 42\n",
    "\n",
    "# bar\n",
    "disable_tqdm = False # True\n",
    "remove_unused_columns = True\n",
    "path_to_outputs = \"./outputs\"\n",
    "\n",
    "# subfolder for model outputs\n",
    "output_dir = path_to_outputs + '/output_dir'\n",
    "overwrite_output_dir = True # False\n",
    "\n",
    "# logs\n",
    "logging_dir = path_to_outputs + '/logging_dir'\n",
    "batch_size = 8#16\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "learning_rate = 1e-4\n",
    "num_train_epochs = 6\n",
    "\n",
    "adam_epsilon = 1e-7\n",
    "\n",
    "fp16 = True\n",
    "\n",
    "# best model\n",
    "load_best_model_at_end = True\n",
    "metric_for_best_model = \"loss\"\n",
    "greater_is_better = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xFxZF6Cii1MF"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9u6Hph99i1Sz"
   },
   "outputs": [],
   "source": [
    "max_length = 300 # The maximum length of a feature (question and context)\n",
    "doc_stride = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vNOUwxnvi1Yi"
   },
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "21e32a4239664ac29fb7fe77f7a54a8a",
      "a7afdc69708a45ef87b9cb76144a1d8b",
      "6093616a3c284d5ea767763a728d8967",
      "2be5b63a59e04da8b8db97adff748e7e",
      "1098c9e9f559482a8630a552e539f179",
      "ea31d46609e347a0b08858b05cc44ec9",
      "17b5e17e6fba42ddbd25f7e1d0de977d",
      "41295ffeaefa4c8f94babe1367107ca5",
      "774400fb34ec4e1ba2f3d8dcf4b7533d",
      "a7f3ccf83df24308af4fa60eea9fa685",
      "bf79f3392be845d39ae7bf9bc9d7f3c7"
     ]
    },
    "id": "m8dyUMvVi1cv",
    "outputId": "ca0af53e-ab16-4ed0-cc69-3ca6b4678492"
   },
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "tokenized_datasets = raw_datasets.map(prepare_train_features, batched=True, remove_columns=raw_datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "to_vUuc4i1gC",
    "outputId": "4169eef6-fba1-420a-d854-413c1ae61689"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForQuestionAnswering: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-large and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\"roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v692UzDHi1mx",
    "outputId": "d6b47f8f-a574-49d2-e090-5a20914cf21e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.embeddings.word_embeddings.weight\n",
      "roberta.embeddings.position_embeddings.weight\n",
      "roberta.embeddings.token_type_embeddings.weight\n",
      "roberta.embeddings.LayerNorm.weight\n",
      "roberta.embeddings.LayerNorm.bias\n",
      "roberta.encoder.layer.0.attention.self.query.weight\n",
      "roberta.encoder.layer.0.attention.self.query.bias\n",
      "roberta.encoder.layer.0.attention.self.key.weight\n",
      "roberta.encoder.layer.0.attention.self.key.bias\n",
      "roberta.encoder.layer.0.attention.self.value.weight\n",
      "roberta.encoder.layer.0.attention.self.value.bias\n",
      "roberta.encoder.layer.0.attention.output.dense.weight\n",
      "roberta.encoder.layer.0.attention.output.dense.bias\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.0.intermediate.dense.weight\n",
      "roberta.encoder.layer.0.intermediate.dense.bias\n",
      "roberta.encoder.layer.0.output.dense.weight\n",
      "roberta.encoder.layer.0.output.dense.bias\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias\n",
      "roberta.encoder.layer.1.attention.self.query.weight\n",
      "roberta.encoder.layer.1.attention.self.query.bias\n",
      "roberta.encoder.layer.1.attention.self.key.weight\n",
      "roberta.encoder.layer.1.attention.self.key.bias\n",
      "roberta.encoder.layer.1.attention.self.value.weight\n",
      "roberta.encoder.layer.1.attention.self.value.bias\n",
      "roberta.encoder.layer.1.attention.output.dense.weight\n",
      "roberta.encoder.layer.1.attention.output.dense.bias\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.1.intermediate.dense.weight\n",
      "roberta.encoder.layer.1.intermediate.dense.bias\n",
      "roberta.encoder.layer.1.output.dense.weight\n",
      "roberta.encoder.layer.1.output.dense.bias\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias\n",
      "roberta.encoder.layer.2.attention.self.query.weight\n",
      "roberta.encoder.layer.2.attention.self.query.bias\n",
      "roberta.encoder.layer.2.attention.self.key.weight\n",
      "roberta.encoder.layer.2.attention.self.key.bias\n",
      "roberta.encoder.layer.2.attention.self.value.weight\n",
      "roberta.encoder.layer.2.attention.self.value.bias\n",
      "roberta.encoder.layer.2.attention.output.dense.weight\n",
      "roberta.encoder.layer.2.attention.output.dense.bias\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.2.intermediate.dense.weight\n",
      "roberta.encoder.layer.2.intermediate.dense.bias\n",
      "roberta.encoder.layer.2.output.dense.weight\n",
      "roberta.encoder.layer.2.output.dense.bias\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias\n",
      "roberta.encoder.layer.3.attention.self.query.weight\n",
      "roberta.encoder.layer.3.attention.self.query.bias\n",
      "roberta.encoder.layer.3.attention.self.key.weight\n",
      "roberta.encoder.layer.3.attention.self.key.bias\n",
      "roberta.encoder.layer.3.attention.self.value.weight\n",
      "roberta.encoder.layer.3.attention.self.value.bias\n",
      "roberta.encoder.layer.3.attention.output.dense.weight\n",
      "roberta.encoder.layer.3.attention.output.dense.bias\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.3.intermediate.dense.weight\n",
      "roberta.encoder.layer.3.intermediate.dense.bias\n",
      "roberta.encoder.layer.3.output.dense.weight\n",
      "roberta.encoder.layer.3.output.dense.bias\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias\n",
      "roberta.encoder.layer.4.attention.self.query.weight\n",
      "roberta.encoder.layer.4.attention.self.query.bias\n",
      "roberta.encoder.layer.4.attention.self.key.weight\n",
      "roberta.encoder.layer.4.attention.self.key.bias\n",
      "roberta.encoder.layer.4.attention.self.value.weight\n",
      "roberta.encoder.layer.4.attention.self.value.bias\n",
      "roberta.encoder.layer.4.attention.output.dense.weight\n",
      "roberta.encoder.layer.4.attention.output.dense.bias\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.4.intermediate.dense.weight\n",
      "roberta.encoder.layer.4.intermediate.dense.bias\n",
      "roberta.encoder.layer.4.output.dense.weight\n",
      "roberta.encoder.layer.4.output.dense.bias\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias\n",
      "roberta.encoder.layer.5.attention.self.query.weight\n",
      "roberta.encoder.layer.5.attention.self.query.bias\n",
      "roberta.encoder.layer.5.attention.self.key.weight\n",
      "roberta.encoder.layer.5.attention.self.key.bias\n",
      "roberta.encoder.layer.5.attention.self.value.weight\n",
      "roberta.encoder.layer.5.attention.self.value.bias\n",
      "roberta.encoder.layer.5.attention.output.dense.weight\n",
      "roberta.encoder.layer.5.attention.output.dense.bias\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.5.intermediate.dense.weight\n",
      "roberta.encoder.layer.5.intermediate.dense.bias\n",
      "roberta.encoder.layer.5.output.dense.weight\n",
      "roberta.encoder.layer.5.output.dense.bias\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias\n",
      "roberta.encoder.layer.6.attention.self.query.weight\n",
      "roberta.encoder.layer.6.attention.self.query.bias\n",
      "roberta.encoder.layer.6.attention.self.key.weight\n",
      "roberta.encoder.layer.6.attention.self.key.bias\n",
      "roberta.encoder.layer.6.attention.self.value.weight\n",
      "roberta.encoder.layer.6.attention.self.value.bias\n",
      "roberta.encoder.layer.6.attention.output.dense.weight\n",
      "roberta.encoder.layer.6.attention.output.dense.bias\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.6.intermediate.dense.weight\n",
      "roberta.encoder.layer.6.intermediate.dense.bias\n",
      "roberta.encoder.layer.6.output.dense.weight\n",
      "roberta.encoder.layer.6.output.dense.bias\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias\n",
      "roberta.encoder.layer.7.attention.self.query.weight\n",
      "roberta.encoder.layer.7.attention.self.query.bias\n",
      "roberta.encoder.layer.7.attention.self.key.weight\n",
      "roberta.encoder.layer.7.attention.self.key.bias\n",
      "roberta.encoder.layer.7.attention.self.value.weight\n",
      "roberta.encoder.layer.7.attention.self.value.bias\n",
      "roberta.encoder.layer.7.attention.output.dense.weight\n",
      "roberta.encoder.layer.7.attention.output.dense.bias\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.7.intermediate.dense.weight\n",
      "roberta.encoder.layer.7.intermediate.dense.bias\n",
      "roberta.encoder.layer.7.output.dense.weight\n",
      "roberta.encoder.layer.7.output.dense.bias\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias\n",
      "roberta.encoder.layer.8.attention.self.query.weight\n",
      "roberta.encoder.layer.8.attention.self.query.bias\n",
      "roberta.encoder.layer.8.attention.self.key.weight\n",
      "roberta.encoder.layer.8.attention.self.key.bias\n",
      "roberta.encoder.layer.8.attention.self.value.weight\n",
      "roberta.encoder.layer.8.attention.self.value.bias\n",
      "roberta.encoder.layer.8.attention.output.dense.weight\n",
      "roberta.encoder.layer.8.attention.output.dense.bias\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.8.intermediate.dense.weight\n",
      "roberta.encoder.layer.8.intermediate.dense.bias\n",
      "roberta.encoder.layer.8.output.dense.weight\n",
      "roberta.encoder.layer.8.output.dense.bias\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias\n",
      "roberta.encoder.layer.9.attention.self.query.weight\n",
      "roberta.encoder.layer.9.attention.self.query.bias\n",
      "roberta.encoder.layer.9.attention.self.key.weight\n",
      "roberta.encoder.layer.9.attention.self.key.bias\n",
      "roberta.encoder.layer.9.attention.self.value.weight\n",
      "roberta.encoder.layer.9.attention.self.value.bias\n",
      "roberta.encoder.layer.9.attention.output.dense.weight\n",
      "roberta.encoder.layer.9.attention.output.dense.bias\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.9.intermediate.dense.weight\n",
      "roberta.encoder.layer.9.intermediate.dense.bias\n",
      "roberta.encoder.layer.9.output.dense.weight\n",
      "roberta.encoder.layer.9.output.dense.bias\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias\n",
      "roberta.encoder.layer.10.attention.self.query.weight\n",
      "roberta.encoder.layer.10.attention.self.query.bias\n",
      "roberta.encoder.layer.10.attention.self.key.weight\n",
      "roberta.encoder.layer.10.attention.self.key.bias\n",
      "roberta.encoder.layer.10.attention.self.value.weight\n",
      "roberta.encoder.layer.10.attention.self.value.bias\n",
      "roberta.encoder.layer.10.attention.output.dense.weight\n",
      "roberta.encoder.layer.10.attention.output.dense.bias\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.10.intermediate.dense.weight\n",
      "roberta.encoder.layer.10.intermediate.dense.bias\n",
      "roberta.encoder.layer.10.output.dense.weight\n",
      "roberta.encoder.layer.10.output.dense.bias\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias\n",
      "roberta.encoder.layer.11.attention.self.query.weight\n",
      "roberta.encoder.layer.11.attention.self.query.bias\n",
      "roberta.encoder.layer.11.attention.self.key.weight\n",
      "roberta.encoder.layer.11.attention.self.key.bias\n",
      "roberta.encoder.layer.11.attention.self.value.weight\n",
      "roberta.encoder.layer.11.attention.self.value.bias\n",
      "roberta.encoder.layer.11.attention.output.dense.weight\n",
      "roberta.encoder.layer.11.attention.output.dense.bias\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.11.intermediate.dense.weight\n",
      "roberta.encoder.layer.11.intermediate.dense.bias\n",
      "roberta.encoder.layer.11.output.dense.weight\n",
      "roberta.encoder.layer.11.output.dense.bias\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias\n",
      "roberta.encoder.layer.12.attention.self.query.weight\n",
      "roberta.encoder.layer.12.attention.self.query.bias\n",
      "roberta.encoder.layer.12.attention.self.key.weight\n",
      "roberta.encoder.layer.12.attention.self.key.bias\n",
      "roberta.encoder.layer.12.attention.self.value.weight\n",
      "roberta.encoder.layer.12.attention.self.value.bias\n",
      "roberta.encoder.layer.12.attention.output.dense.weight\n",
      "roberta.encoder.layer.12.attention.output.dense.bias\n",
      "roberta.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.12.intermediate.dense.weight\n",
      "roberta.encoder.layer.12.intermediate.dense.bias\n",
      "roberta.encoder.layer.12.output.dense.weight\n",
      "roberta.encoder.layer.12.output.dense.bias\n",
      "roberta.encoder.layer.12.output.LayerNorm.weight\n",
      "roberta.encoder.layer.12.output.LayerNorm.bias\n",
      "roberta.encoder.layer.13.attention.self.query.weight\n",
      "roberta.encoder.layer.13.attention.self.query.bias\n",
      "roberta.encoder.layer.13.attention.self.key.weight\n",
      "roberta.encoder.layer.13.attention.self.key.bias\n",
      "roberta.encoder.layer.13.attention.self.value.weight\n",
      "roberta.encoder.layer.13.attention.self.value.bias\n",
      "roberta.encoder.layer.13.attention.output.dense.weight\n",
      "roberta.encoder.layer.13.attention.output.dense.bias\n",
      "roberta.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.13.intermediate.dense.weight\n",
      "roberta.encoder.layer.13.intermediate.dense.bias\n",
      "roberta.encoder.layer.13.output.dense.weight\n",
      "roberta.encoder.layer.13.output.dense.bias\n",
      "roberta.encoder.layer.13.output.LayerNorm.weight\n",
      "roberta.encoder.layer.13.output.LayerNorm.bias\n",
      "roberta.encoder.layer.14.attention.self.query.weight\n",
      "roberta.encoder.layer.14.attention.self.query.bias\n",
      "roberta.encoder.layer.14.attention.self.key.weight\n",
      "roberta.encoder.layer.14.attention.self.key.bias\n",
      "roberta.encoder.layer.14.attention.self.value.weight\n",
      "roberta.encoder.layer.14.attention.self.value.bias\n",
      "roberta.encoder.layer.14.attention.output.dense.weight\n",
      "roberta.encoder.layer.14.attention.output.dense.bias\n",
      "roberta.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.14.intermediate.dense.weight\n",
      "roberta.encoder.layer.14.intermediate.dense.bias\n",
      "roberta.encoder.layer.14.output.dense.weight\n",
      "roberta.encoder.layer.14.output.dense.bias\n",
      "roberta.encoder.layer.14.output.LayerNorm.weight\n",
      "roberta.encoder.layer.14.output.LayerNorm.bias\n",
      "roberta.encoder.layer.15.attention.self.query.weight\n",
      "roberta.encoder.layer.15.attention.self.query.bias\n",
      "roberta.encoder.layer.15.attention.self.key.weight\n",
      "roberta.encoder.layer.15.attention.self.key.bias\n",
      "roberta.encoder.layer.15.attention.self.value.weight\n",
      "roberta.encoder.layer.15.attention.self.value.bias\n",
      "roberta.encoder.layer.15.attention.output.dense.weight\n",
      "roberta.encoder.layer.15.attention.output.dense.bias\n",
      "roberta.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.15.intermediate.dense.weight\n",
      "roberta.encoder.layer.15.intermediate.dense.bias\n",
      "roberta.encoder.layer.15.output.dense.weight\n",
      "roberta.encoder.layer.15.output.dense.bias\n",
      "roberta.encoder.layer.15.output.LayerNorm.weight\n",
      "roberta.encoder.layer.15.output.LayerNorm.bias\n",
      "roberta.encoder.layer.16.attention.self.query.weight\n",
      "roberta.encoder.layer.16.attention.self.query.bias\n",
      "roberta.encoder.layer.16.attention.self.key.weight\n",
      "roberta.encoder.layer.16.attention.self.key.bias\n",
      "roberta.encoder.layer.16.attention.self.value.weight\n",
      "roberta.encoder.layer.16.attention.self.value.bias\n",
      "roberta.encoder.layer.16.attention.output.dense.weight\n",
      "roberta.encoder.layer.16.attention.output.dense.bias\n",
      "roberta.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.16.intermediate.dense.weight\n",
      "roberta.encoder.layer.16.intermediate.dense.bias\n",
      "roberta.encoder.layer.16.output.dense.weight\n",
      "roberta.encoder.layer.16.output.dense.bias\n",
      "roberta.encoder.layer.16.output.LayerNorm.weight\n",
      "roberta.encoder.layer.16.output.LayerNorm.bias\n",
      "roberta.encoder.layer.17.attention.self.query.weight\n",
      "roberta.encoder.layer.17.attention.self.query.bias\n",
      "roberta.encoder.layer.17.attention.self.key.weight\n",
      "roberta.encoder.layer.17.attention.self.key.bias\n",
      "roberta.encoder.layer.17.attention.self.value.weight\n",
      "roberta.encoder.layer.17.attention.self.value.bias\n",
      "roberta.encoder.layer.17.attention.output.dense.weight\n",
      "roberta.encoder.layer.17.attention.output.dense.bias\n",
      "roberta.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.17.intermediate.dense.weight\n",
      "roberta.encoder.layer.17.intermediate.dense.bias\n",
      "roberta.encoder.layer.17.output.dense.weight\n",
      "roberta.encoder.layer.17.output.dense.bias\n",
      "roberta.encoder.layer.17.output.LayerNorm.weight\n",
      "roberta.encoder.layer.17.output.LayerNorm.bias\n",
      "roberta.encoder.layer.18.attention.self.query.weight\n",
      "roberta.encoder.layer.18.attention.self.query.bias\n",
      "roberta.encoder.layer.18.attention.self.key.weight\n",
      "roberta.encoder.layer.18.attention.self.key.bias\n",
      "roberta.encoder.layer.18.attention.self.value.weight\n",
      "roberta.encoder.layer.18.attention.self.value.bias\n",
      "roberta.encoder.layer.18.attention.output.dense.weight\n",
      "roberta.encoder.layer.18.attention.output.dense.bias\n",
      "roberta.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.18.intermediate.dense.weight\n",
      "roberta.encoder.layer.18.intermediate.dense.bias\n",
      "roberta.encoder.layer.18.output.dense.weight\n",
      "roberta.encoder.layer.18.output.dense.bias\n",
      "roberta.encoder.layer.18.output.LayerNorm.weight\n",
      "roberta.encoder.layer.18.output.LayerNorm.bias\n",
      "roberta.encoder.layer.19.attention.self.query.weight\n",
      "roberta.encoder.layer.19.attention.self.query.bias\n",
      "roberta.encoder.layer.19.attention.self.key.weight\n",
      "roberta.encoder.layer.19.attention.self.key.bias\n",
      "roberta.encoder.layer.19.attention.self.value.weight\n",
      "roberta.encoder.layer.19.attention.self.value.bias\n",
      "roberta.encoder.layer.19.attention.output.dense.weight\n",
      "roberta.encoder.layer.19.attention.output.dense.bias\n",
      "roberta.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.19.intermediate.dense.weight\n",
      "roberta.encoder.layer.19.intermediate.dense.bias\n",
      "roberta.encoder.layer.19.output.dense.weight\n",
      "roberta.encoder.layer.19.output.dense.bias\n",
      "roberta.encoder.layer.19.output.LayerNorm.weight\n",
      "roberta.encoder.layer.19.output.LayerNorm.bias\n",
      "roberta.encoder.layer.20.attention.self.query.weight\n",
      "roberta.encoder.layer.20.attention.self.query.bias\n",
      "roberta.encoder.layer.20.attention.self.key.weight\n",
      "roberta.encoder.layer.20.attention.self.key.bias\n",
      "roberta.encoder.layer.20.attention.self.value.weight\n",
      "roberta.encoder.layer.20.attention.self.value.bias\n",
      "roberta.encoder.layer.20.attention.output.dense.weight\n",
      "roberta.encoder.layer.20.attention.output.dense.bias\n",
      "roberta.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.20.intermediate.dense.weight\n",
      "roberta.encoder.layer.20.intermediate.dense.bias\n",
      "roberta.encoder.layer.20.output.dense.weight\n",
      "roberta.encoder.layer.20.output.dense.bias\n",
      "roberta.encoder.layer.20.output.LayerNorm.weight\n",
      "roberta.encoder.layer.20.output.LayerNorm.bias\n",
      "roberta.encoder.layer.21.attention.self.query.weight\n",
      "roberta.encoder.layer.21.attention.self.query.bias\n",
      "roberta.encoder.layer.21.attention.self.key.weight\n",
      "roberta.encoder.layer.21.attention.self.key.bias\n",
      "roberta.encoder.layer.21.attention.self.value.weight\n",
      "roberta.encoder.layer.21.attention.self.value.bias\n",
      "roberta.encoder.layer.21.attention.output.dense.weight\n",
      "roberta.encoder.layer.21.attention.output.dense.bias\n",
      "roberta.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.21.intermediate.dense.weight\n",
      "roberta.encoder.layer.21.intermediate.dense.bias\n",
      "roberta.encoder.layer.21.output.dense.weight\n",
      "roberta.encoder.layer.21.output.dense.bias\n",
      "roberta.encoder.layer.21.output.LayerNorm.weight\n",
      "roberta.encoder.layer.21.output.LayerNorm.bias\n",
      "roberta.encoder.layer.22.attention.self.query.weight\n",
      "roberta.encoder.layer.22.attention.self.query.bias\n",
      "roberta.encoder.layer.22.attention.self.key.weight\n",
      "roberta.encoder.layer.22.attention.self.key.bias\n",
      "roberta.encoder.layer.22.attention.self.value.weight\n",
      "roberta.encoder.layer.22.attention.self.value.bias\n",
      "roberta.encoder.layer.22.attention.output.dense.weight\n",
      "roberta.encoder.layer.22.attention.output.dense.bias\n",
      "roberta.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.22.intermediate.dense.weight\n",
      "roberta.encoder.layer.22.intermediate.dense.bias\n",
      "roberta.encoder.layer.22.output.dense.weight\n",
      "roberta.encoder.layer.22.output.dense.bias\n",
      "roberta.encoder.layer.22.output.LayerNorm.weight\n",
      "roberta.encoder.layer.22.output.LayerNorm.bias\n",
      "roberta.encoder.layer.23.attention.self.query.weight\n",
      "roberta.encoder.layer.23.attention.self.query.bias\n",
      "roberta.encoder.layer.23.attention.self.key.weight\n",
      "roberta.encoder.layer.23.attention.self.key.bias\n",
      "roberta.encoder.layer.23.attention.self.value.weight\n",
      "roberta.encoder.layer.23.attention.self.value.bias\n",
      "roberta.encoder.layer.23.attention.output.dense.weight\n",
      "roberta.encoder.layer.23.attention.output.dense.bias\n",
      "roberta.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.23.intermediate.dense.weight\n",
      "roberta.encoder.layer.23.intermediate.dense.bias\n",
      "roberta.encoder.layer.23.output.dense.weight\n",
      "roberta.encoder.layer.23.output.dense.bias\n",
      "roberta.encoder.layer.23.output.LayerNorm.weight\n",
      "roberta.encoder.layer.23.output.LayerNorm.bias\n",
      "qa_outputs.weight\n",
      "qa_outputs.bias\n"
     ]
    }
   ],
   "source": [
    " for name, p in model.named_parameters():\n",
    "   if p.requires_grad == True:\n",
    "     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7GPNHacLO-9x",
    "outputId": "f7813402-7628-48d5-f68d-ec0388071ff5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354312194"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rPIPqMQoeL9d"
   },
   "outputs": [],
   "source": [
    "from transformers.adapters.configuration import ParallelConfig\n",
    "\n",
    "adapter_non_linearity = 'relu'\n",
    "adapter_reduction_factor = 64\n",
    "leave_out = []\n",
    "task_name = \"squad\"\n",
    "adapter_config = ParallelConfig(scaling=\"learned\", non_linearity=adapter_non_linearity,\n",
    "                                reduction_factor=adapter_reduction_factor,)\n",
    "model.add_adapter(task_name, config=adapter_config)\n",
    "model.set_active_adapters(task_name)\n",
    "model.train_adapter([task_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wt9bkfHCi1sm",
    "outputId": "e690e6ac-3855-4719-ccfd-95e04d3b5881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.encoder.layer.0.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.0.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.0.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.0.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.0.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.1.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.1.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.1.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.1.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.1.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.2.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.2.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.2.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.2.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.2.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.3.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.3.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.3.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.3.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.3.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.4.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.4.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.4.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.4.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.4.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.5.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.5.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.5.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.5.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.5.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.6.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.6.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.6.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.6.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.6.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.7.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.7.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.7.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.7.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.7.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.8.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.8.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.8.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.8.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.8.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.9.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.9.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.9.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.9.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.9.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.10.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.10.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.10.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.10.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.10.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.11.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.11.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.11.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.11.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.11.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.12.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.12.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.12.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.12.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.12.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.13.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.13.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.13.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.13.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.13.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.14.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.14.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.14.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.14.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.14.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.15.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.15.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.15.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.15.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.15.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.16.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.16.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.16.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.16.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.16.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.17.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.17.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.17.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.17.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.17.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.18.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.18.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.18.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.18.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.18.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.19.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.19.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.19.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.19.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.19.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.20.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.20.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.20.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.20.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.20.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.21.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.21.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.21.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.21.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.21.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.22.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.22.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.22.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.22.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.22.output.adapters.squad.adapter_up.bias\n",
      "roberta.encoder.layer.23.output.adapters.squad.scaling\n",
      "roberta.encoder.layer.23.output.adapters.squad.adapter_down.0.weight\n",
      "roberta.encoder.layer.23.output.adapters.squad.adapter_down.0.bias\n",
      "roberta.encoder.layer.23.output.adapters.squad.adapter_up.weight\n",
      "roberta.encoder.layer.23.output.adapters.squad.adapter_up.bias\n",
      "qa_outputs.weight\n",
      "qa_outputs.bias\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "  if p.requires_grad == True:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EydRPwBYMOfm",
    "outputId": "52094c60-3dfd-4e0a-9871-2b0b0d71e733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813466"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kzXI906Li1vm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=overwrite_output_dir,\n",
    "        do_train=do_train,\n",
    "        do_eval=do_eval,\n",
    "        evaluation_strategy=evaluation_strategy,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        adam_beta1=adam_beta1,\n",
    "        adam_beta2=adam_beta2,\n",
    "        adam_epsilon=adam_epsilon,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        lr_scheduler_type=lr_scheduler_type,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        warmup_steps=warmup_steps,\n",
    "        logging_dir=logging_dir,         # directory for storing logs\n",
    "        logging_strategy=evaluation_strategy,\n",
    "        logging_steps=logging_steps,     # if strategy = \"steps\"\n",
    "        save_strategy=evaluation_strategy,          # model checkpoint saving strategy\n",
    "        save_steps=logging_steps,        # if strategy = \"steps\"\n",
    "        save_total_limit=save_total_limit,\n",
    "        fp16=fp16,\n",
    "        eval_steps=logging_steps,        # if strategy = \"steps\"\n",
    "        load_best_model_at_end=load_best_model_at_end,\n",
    "        metric_for_best_model=metric_for_best_model,\n",
    "        greater_is_better=greater_is_better\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDfs7ZXglKXc",
    "outputId": "98e9b7e3-4a7c-4cc1-ea4d-88a717d1c30b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator\n",
    "train_adapter=True\n",
    "#do_save_full_model=train_adapter, # save full model as we finetuned head + embeddings\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "5_ms6goslKep",
    "outputId": "c99dadc0-e76e-45ec-c1de-be2ff82a101f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarath/anaconda3/envs/dl/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 136788\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 102594\n",
      "  Number of trainable parameters = 813466\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='102594' max='102594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [102594/102594 2:03:21, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.992800</td>\n",
       "      <td>0.708844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.743200</td>\n",
       "      <td>0.646711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.692248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.633800</td>\n",
       "      <td>0.662540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.600700</td>\n",
       "      <td>0.659869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.683546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12711\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs/output_dir/checkpoint-17099\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-17099/squad/adapter_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-17099/squad/pytorch_adapter.bin\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-17099/squad/head_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-17099/squad/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./outputs/output_dir/checkpoint-17099/tokenizer_config.json\n",
      "Special tokens file saved in ./outputs/output_dir/checkpoint-17099/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12711\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs/output_dir/checkpoint-34198\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-34198/squad/adapter_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-34198/squad/pytorch_adapter.bin\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-34198/squad/head_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-34198/squad/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./outputs/output_dir/checkpoint-34198/tokenizer_config.json\n",
      "Special tokens file saved in ./outputs/output_dir/checkpoint-34198/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12711\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs/output_dir/checkpoint-51297\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-51297/squad/adapter_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-51297/squad/pytorch_adapter.bin\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-51297/squad/head_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-51297/squad/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./outputs/output_dir/checkpoint-51297/tokenizer_config.json\n",
      "Special tokens file saved in ./outputs/output_dir/checkpoint-51297/special_tokens_map.json\n",
      "Deleting older checkpoint [outputs/output_dir/checkpoint-17099] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12711\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs/output_dir/checkpoint-68396\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-68396/squad/adapter_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-68396/squad/pytorch_adapter.bin\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-68396/squad/head_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-68396/squad/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./outputs/output_dir/checkpoint-68396/tokenizer_config.json\n",
      "Special tokens file saved in ./outputs/output_dir/checkpoint-68396/special_tokens_map.json\n",
      "Deleting older checkpoint [outputs/output_dir/checkpoint-51297] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12711\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs/output_dir/checkpoint-85495\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-85495/squad/adapter_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-85495/squad/pytorch_adapter.bin\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-85495/squad/head_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-85495/squad/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./outputs/output_dir/checkpoint-85495/tokenizer_config.json\n",
      "Special tokens file saved in ./outputs/output_dir/checkpoint-85495/special_tokens_map.json\n",
      "Deleting older checkpoint [outputs/output_dir/checkpoint-68396] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12711\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./outputs/output_dir/checkpoint-102594\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-102594/squad/adapter_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-102594/squad/pytorch_adapter.bin\n",
      "Configuration saved in ./outputs/output_dir/checkpoint-102594/squad/head_config.json\n",
      "Module weights saved in ./outputs/output_dir/checkpoint-102594/squad/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./outputs/output_dir/checkpoint-102594/tokenizer_config.json\n",
      "Special tokens file saved in ./outputs/output_dir/checkpoint-102594/special_tokens_map.json\n",
      "Deleting older checkpoint [outputs/output_dir/checkpoint-85495] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./outputs/output_dir/checkpoint-34198 (score: 0.6467106938362122).\n",
      "Loading module configuration from ./outputs/output_dir/checkpoint-34198/squad/adapter_config.json\n",
      "Overwriting existing adapter 'squad'.\n",
      "Loading module weights from ./outputs/output_dir/checkpoint-34198/squad/pytorch_adapter.bin\n",
      "Loading module configuration from ./outputs/output_dir/checkpoint-34198/squad/head_config.json\n",
      "Loading module weights from ./outputs/output_dir/checkpoint-34198/squad/pytorch_model_head.bin\n",
      "Deleting older checkpoint [outputs/output_dir/checkpoint-34198] due to args.save_total_limit\n",
      "Deleting older checkpoint [outputs/output_dir/checkpoint-102594] due to args.save_total_limit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=102594, training_loss=0.7039059815723873, metrics={'train_runtime': 7402.0994, 'train_samples_per_second': 110.878, 'train_steps_per_second': 13.86, 'total_flos': 4.47809552495856e+17, 'train_loss': 0.7039059815723873, 'epoch': 6.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EAvMZcC2lKlp"
   },
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples):\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "82eed285c68c4b34a529cbd97a87f263",
      "35d81edaa4fd448dacf5ca54d13d3052",
      "cdf913e2ee334def95a0be528ee18615",
      "946b3aa900334781a83dd935799028bc",
      "f32edc8eba7144bb862a8fdbc55b2f40",
      "1c5f31ea367e4c8c93e496690fff41c4",
      "ef3067b7292244eab73617030b2dc474",
      "9fdb1006487144298c74aa02333d4a7f",
      "085c2682f50a4e1eb1c827d2d92ac872",
      "38627d2f46e3428ea23e89d1d1020e4c",
      "aede203c4b774d00880421c67b630c3c"
     ]
    },
    "id": "cU5qHvPClKru",
    "outputId": "0ae5d9d9-b1ef-4430-dd1b-092e4d8a9d9f"
   },
   "outputs": [],
   "source": [
    "validation_features = raw_datasets[\"validation\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "0Bv8lYy_lK0S",
    "outputId": "497d0989-0a03-4581-c5fc-99852f622e66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 12711\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "SmPSSrjdlZ6k"
   },
   "outputs": [],
   "source": [
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ESA80lcQlaCw"
   },
   "outputs": [],
   "source": [
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "j5jSx142laJU"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import collections\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    # Build a map example to its corresponding features.\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    # The dictionaries we have to fill.\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # Logging.\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    # Let's loop over all the examples!\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        # Those are the indices of the features associated to the current example.\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "\n",
    "        context = example[\"context\"]\n",
    "        # Looping through all the features associated to the current example.\n",
    "        for feature_index in feature_indices:\n",
    "            # We grab the predictions of the model for this feature.\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "            # context.\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # Update minimum null prediction.\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                    # to part of the input_ids that are not in the context.\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
    "            # failure.\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
    "        #if not squad_v2:\n",
    "        #    predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        #else:\n",
    "        answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "        predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "57e214c6c5c540b18ec86c99bee1a10e",
      "58c40dba4d03448aac14a70e55073ebc",
      "a4156e5305774fe9a8ff6121fc4fef65",
      "7a8e9ec1b36a4dd18d8938e354e0224d",
      "3fef105b0184469892ae373e69298935",
      "06b8be90b1c14026af86fe609b7ad799",
      "d55ecc441c15428c80094c40aa1d7173",
      "de06396baf154658a661a89c50be55a1",
      "326d05ce87934dab898394d987b198b2",
      "6689db4856674c879151ea3e99de9323",
      "87d7551f7e6249cbaebe2892e891e0f9"
     ]
    },
    "id": "hgpUGYW-laPr",
    "outputId": "30fd5f8b-0ac8-4079-b7b0-9b1550f1ac16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 11873 example predictions split into 12711 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11873/11873 [00:08<00:00, 1370.27it/s]\n"
     ]
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(raw_datasets[\"validation\"], validation_features, raw_predictions.predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356,
     "referenced_widgets": [
      "472d829c4f2747e4b70de43c89a8a779",
      "baa0ba745c2c4ea7b59164865c0c438f",
      "d7bff0ad32fa4d63a67f7d71c6a8ba55",
      "ff504abb3c4f4d35a2198d906acf49e8",
      "6bd02c43b7164c469035ae6c31d7e8fb",
      "734f5006de024cdb8e28dfc5f6538eb2",
      "0eca645e34d7419ebaa0966c87eab01b",
      "b83925ef0fee4e4c8a6d663159b7d3c6",
      "afe41e33cce2435086b773ce5d860a80",
      "1f62598fb4a14ce385c92f241ba0ac6a",
      "8a1cec50d4604fd1bbae0ef1ee83d90c",
      "a1211e9fcecd4cd5bff22cd4accc4a76",
      "d464230067254bfea92c79aa67cc3639",
      "88cfac655d9c4977aa19af2097cd7d38",
      "b55e6e03cf9e4fc7b427084b90d4dca5",
      "02fbfda565dd4469b2af14eb6d4c0641",
      "5a6b3db1b9c14bec85f1ef4f7bf08de8",
      "348855cc3c7a45568e4a35e46e7db1d5",
      "9f5112d66d044e6088f9aa20f1b80aca",
      "7e61ffe801214d1eade8258add479bee",
      "2d3ef180a06f4465bdf846f788a8c3c5",
      "b1a1490737f7400b9c297b51b8caaf5b"
     ]
    },
    "id": "gUVqlMwIlaVg",
    "outputId": "69e68986-ccaa-4756-d506-0f695044d053"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5226/3461119883.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library  Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad_v2\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact': 83.17190263623347,\n",
       " 'f1': 86.18698935577652,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 78.66059379217273,\n",
       " 'HasAns_f1': 84.69941373500916,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 87.67031118587047,\n",
       " 'NoAns_f1': 87.67031118587047,\n",
       " 'NoAns_total': 5945,\n",
       " 'best_exact': 83.17190263623347,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 86.18698935577635,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"squad_v2\")\n",
    "formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in raw_datasets[\"validation\"]]\n",
    "metric.compute(predictions=formatted_predictions, references=references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xzfz-N-zfLM6",
    "outputId": "296d1c49-3110-4878-c282-a341713c98fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./saved_model/adapter_config.json\n",
      "Module weights saved in ./saved_model/pytorch_adapter.bin\n",
      "Configuration saved in ./saved_model/head_config.json\n",
      "Module weights saved in ./saved_model/pytorch_model_head.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.model.save_adapter(\"./saved_model\", adapter_name=\"squad\", with_head=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02fbfda565dd4469b2af14eb6d4c0641": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06b8be90b1c14026af86fe609b7ad799": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "085c2682f50a4e1eb1c827d2d92ac872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0eca645e34d7419ebaa0966c87eab01b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1098c9e9f559482a8630a552e539f179": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17b5e17e6fba42ddbd25f7e1d0de977d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c5f31ea367e4c8c93e496690fff41c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f62598fb4a14ce385c92f241ba0ac6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21e32a4239664ac29fb7fe77f7a54a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7afdc69708a45ef87b9cb76144a1d8b",
       "IPY_MODEL_6093616a3c284d5ea767763a728d8967",
       "IPY_MODEL_2be5b63a59e04da8b8db97adff748e7e"
      ],
      "layout": "IPY_MODEL_1098c9e9f559482a8630a552e539f179"
     }
    },
    "2be5b63a59e04da8b8db97adff748e7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7f3ccf83df24308af4fa60eea9fa685",
      "placeholder": "",
      "style": "IPY_MODEL_bf79f3392be845d39ae7bf9bc9d7f3c7",
      "value": " 11873/11873 [00:14&lt;00:00, 1245.86 examples/s]"
     }
    },
    "2d3ef180a06f4465bdf846f788a8c3c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "326d05ce87934dab898394d987b198b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "348855cc3c7a45568e4a35e46e7db1d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35d81edaa4fd448dacf5ca54d13d3052": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c5f31ea367e4c8c93e496690fff41c4",
      "placeholder": "",
      "style": "IPY_MODEL_ef3067b7292244eab73617030b2dc474",
      "value": "Map: 100%"
     }
    },
    "38627d2f46e3428ea23e89d1d1020e4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fef105b0184469892ae373e69298935": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41295ffeaefa4c8f94babe1367107ca5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "472d829c4f2747e4b70de43c89a8a779": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_baa0ba745c2c4ea7b59164865c0c438f",
       "IPY_MODEL_d7bff0ad32fa4d63a67f7d71c6a8ba55",
       "IPY_MODEL_ff504abb3c4f4d35a2198d906acf49e8"
      ],
      "layout": "IPY_MODEL_6bd02c43b7164c469035ae6c31d7e8fb"
     }
    },
    "57e214c6c5c540b18ec86c99bee1a10e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c40dba4d03448aac14a70e55073ebc",
       "IPY_MODEL_a4156e5305774fe9a8ff6121fc4fef65",
       "IPY_MODEL_7a8e9ec1b36a4dd18d8938e354e0224d"
      ],
      "layout": "IPY_MODEL_3fef105b0184469892ae373e69298935"
     }
    },
    "58c40dba4d03448aac14a70e55073ebc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06b8be90b1c14026af86fe609b7ad799",
      "placeholder": "",
      "style": "IPY_MODEL_d55ecc441c15428c80094c40aa1d7173",
      "value": "100%"
     }
    },
    "5a6b3db1b9c14bec85f1ef4f7bf08de8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6093616a3c284d5ea767763a728d8967": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41295ffeaefa4c8f94babe1367107ca5",
      "max": 11873,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_774400fb34ec4e1ba2f3d8dcf4b7533d",
      "value": 11873
     }
    },
    "6689db4856674c879151ea3e99de9323": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bd02c43b7164c469035ae6c31d7e8fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "734f5006de024cdb8e28dfc5f6538eb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "774400fb34ec4e1ba2f3d8dcf4b7533d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a8e9ec1b36a4dd18d8938e354e0224d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6689db4856674c879151ea3e99de9323",
      "placeholder": "",
      "style": "IPY_MODEL_87d7551f7e6249cbaebe2892e891e0f9",
      "value": " 11873/11873 [00:38&lt;00:00, 441.76it/s]"
     }
    },
    "7e61ffe801214d1eade8258add479bee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82eed285c68c4b34a529cbd97a87f263": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35d81edaa4fd448dacf5ca54d13d3052",
       "IPY_MODEL_cdf913e2ee334def95a0be528ee18615",
       "IPY_MODEL_946b3aa900334781a83dd935799028bc"
      ],
      "layout": "IPY_MODEL_f32edc8eba7144bb862a8fdbc55b2f40"
     }
    },
    "87d7551f7e6249cbaebe2892e891e0f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88cfac655d9c4977aa19af2097cd7d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f5112d66d044e6088f9aa20f1b80aca",
      "max": 3188,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e61ffe801214d1eade8258add479bee",
      "value": 3188
     }
    },
    "8a1cec50d4604fd1bbae0ef1ee83d90c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "946b3aa900334781a83dd935799028bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38627d2f46e3428ea23e89d1d1020e4c",
      "placeholder": "",
      "style": "IPY_MODEL_aede203c4b774d00880421c67b630c3c",
      "value": " 11873/11873 [00:18&lt;00:00, 547.78 examples/s]"
     }
    },
    "9f5112d66d044e6088f9aa20f1b80aca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fdb1006487144298c74aa02333d4a7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1211e9fcecd4cd5bff22cd4accc4a76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d464230067254bfea92c79aa67cc3639",
       "IPY_MODEL_88cfac655d9c4977aa19af2097cd7d38",
       "IPY_MODEL_b55e6e03cf9e4fc7b427084b90d4dca5"
      ],
      "layout": "IPY_MODEL_02fbfda565dd4469b2af14eb6d4c0641"
     }
    },
    "a4156e5305774fe9a8ff6121fc4fef65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de06396baf154658a661a89c50be55a1",
      "max": 11873,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_326d05ce87934dab898394d987b198b2",
      "value": 11873
     }
    },
    "a7afdc69708a45ef87b9cb76144a1d8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea31d46609e347a0b08858b05cc44ec9",
      "placeholder": "",
      "style": "IPY_MODEL_17b5e17e6fba42ddbd25f7e1d0de977d",
      "value": "Map: 100%"
     }
    },
    "a7f3ccf83df24308af4fa60eea9fa685": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aede203c4b774d00880421c67b630c3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afe41e33cce2435086b773ce5d860a80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1a1490737f7400b9c297b51b8caaf5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b55e6e03cf9e4fc7b427084b90d4dca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d3ef180a06f4465bdf846f788a8c3c5",
      "placeholder": "",
      "style": "IPY_MODEL_b1a1490737f7400b9c297b51b8caaf5b",
      "value": " 11.3k/? [00:00&lt;00:00, 779kB/s]"
     }
    },
    "b83925ef0fee4e4c8a6d663159b7d3c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baa0ba745c2c4ea7b59164865c0c438f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_734f5006de024cdb8e28dfc5f6538eb2",
      "placeholder": "",
      "style": "IPY_MODEL_0eca645e34d7419ebaa0966c87eab01b",
      "value": "Downloading builder script: "
     }
    },
    "bf79f3392be845d39ae7bf9bc9d7f3c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdf913e2ee334def95a0be528ee18615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fdb1006487144298c74aa02333d4a7f",
      "max": 11873,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_085c2682f50a4e1eb1c827d2d92ac872",
      "value": 11873
     }
    },
    "d464230067254bfea92c79aa67cc3639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a6b3db1b9c14bec85f1ef4f7bf08de8",
      "placeholder": "",
      "style": "IPY_MODEL_348855cc3c7a45568e4a35e46e7db1d5",
      "value": "Downloading extra modules: "
     }
    },
    "d55ecc441c15428c80094c40aa1d7173": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7bff0ad32fa4d63a67f7d71c6a8ba55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b83925ef0fee4e4c8a6d663159b7d3c6",
      "max": 2253,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afe41e33cce2435086b773ce5d860a80",
      "value": 2253
     }
    },
    "de06396baf154658a661a89c50be55a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea31d46609e347a0b08858b05cc44ec9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef3067b7292244eab73617030b2dc474": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f32edc8eba7144bb862a8fdbc55b2f40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff504abb3c4f4d35a2198d906acf49e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f62598fb4a14ce385c92f241ba0ac6a",
      "placeholder": "",
      "style": "IPY_MODEL_8a1cec50d4604fd1bbae0ef1ee83d90c",
      "value": " 6.46k/? [00:00&lt;00:00, 311kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
