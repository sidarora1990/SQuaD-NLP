{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEw69hRkeL9S"
      },
      "source": [
        "### Fine-tuning roberta large on Squad dataset for question-answering using adapter-lora concept -Hemant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCuwzR8HihOY",
        "outputId": "277d0c7c-1109-4a3d-cca0-4c52470d7288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adapter-transformers\n",
            "  Downloading adapter_transformers-3.2.1-py3-none-any.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from adapter-transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from adapter-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, xxhash, dill, multiprocess, huggingface-hub, adapter-transformers, datasets\n",
            "Successfully installed adapter-transformers-3.2.1 datasets-2.14.5 dill-0.3.7 huggingface-hub-0.17.3 multiprocess-0.70.15 tokenizers-0.13.3 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U adapter-transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HJ04ipQ3-kmV"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, AdapterTrainer, EvalPrediction\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "raw_datasets = load_dataset('squad_v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDKXvVoCizhO",
        "outputId": "5b6ebdba-cdf1-451b-ba0e-3b5125d2c7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘outputs’: File exists\n",
            "mkdir: cannot create directory ‘saved_model’: File exists\n",
            "mkdir: cannot create directory ‘outputs/output_dir’: File exists\n",
            "mkdir: cannot create directory ‘outputs/logging_dir’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir outputs\n",
        "!mkdir saved_model\n",
        "!mkdir outputs/output_dir\n",
        "!mkdir outputs/logging_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xACyNsDYi1EO"
      },
      "outputs": [],
      "source": [
        "do_train = True # False\n",
        "do_eval = True\n",
        "\n",
        "# epochs, bs, GA\n",
        "#evaluation_strategy = \"epoch\" # no\n",
        "evaluation_strategy = \"no\"\n",
        "\n",
        "# fp16\n",
        "fp16_opt_level = 'O1'\n",
        "fp16_backend = \"auto\"\n",
        "fp16_full_eval = False\n",
        "\n",
        "# optimizer (AdamW)\n",
        "weight_decay = 0.01 # 0.0\n",
        "adam_beta1 = 0.9\n",
        "adam_beta2 = 0.999\n",
        "\n",
        "# scheduler\n",
        "lr_scheduler_type = 'linear'\n",
        "warmup_ratio = 0.0\n",
        "warmup_steps = 0\n",
        "\n",
        "# logs\n",
        "logging_strategy = \"steps\"\n",
        "logging_first_step = True # False\n",
        "logging_steps = 500     # if strategy = \"steps\"\n",
        "eval_steps = logging_steps # logging_steps\n",
        "\n",
        "# checkpoints\n",
        "#save_strategy = \"epoch\" # steps\n",
        "save_strategy = \"steps\" # steps\n",
        "save_steps = 1000 # if save_strategy = \"steps\"\n",
        "save_total_limit = 1 # None\n",
        "\n",
        "# no cuda, seed\n",
        "no_cuda = False\n",
        "seed = 42\n",
        "\n",
        "# bar\n",
        "disable_tqdm = False # True\n",
        "remove_unused_columns = True\n",
        "path_to_outputs = \"./outputs\"\n",
        "\n",
        "# subfolder for model outputs\n",
        "output_dir = path_to_outputs + '/output_dir'\n",
        "overwrite_output_dir = True # False\n",
        "\n",
        "# logs\n",
        "logging_dir = path_to_outputs + '/logging_dir'\n",
        "batch_size = 4#16\n",
        "gradient_accumulation_steps = 1\n",
        "\n",
        "learning_rate = 1e-4\n",
        "#num_train_epochs = 6\n",
        "max_steps = 10\n",
        "\n",
        "adam_epsilon = 1e-7\n",
        "\n",
        "fp16 = True\n",
        "\n",
        "# best model\n",
        "load_best_model_at_end = True\n",
        "metric_for_best_model = \"loss\"\n",
        "greater_is_better = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xFxZF6Cii1MF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e29277-a468-47f2-e0d7-8f5cfb873957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-large\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-large\")"
      ],
      "metadata": {
        "id": "VFw8O-DggP-E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = model.get_input_embeddings().weight.shape[0]\n",
        "if len(tokenizer) > embedding_size:\n",
        "  model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "if model.config.decoder_start_token_id is None:\n",
        "  raise ValueError(\"Make sure that `config.decoder_start_token_id` is correctly defined\")"
      ],
      "metadata": {
        "id": "J9c00SmHg7kk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 300 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128\n",
        "max_answer_length = 30\n",
        "padding = \"max_length\"\n",
        "max_seq_length = min(max_length, tokenizer.model_max_length)\n",
        "column_names = raw_datasets[\"train\"].column_names\n",
        "question_column = \"question\"\n",
        "context_column = \"context\"\n",
        "answer_column = \"answers\""
      ],
      "metadata": {
        "id": "49CUppGXhC41"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9u6Hph99i1Sz"
      },
      "outputs": [],
      "source": [
        "train_dataset = raw_datasets[\"train\"]\n",
        "eval_examples = raw_datasets[\"validation\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brC02NpLiHcP",
        "outputId": "989f333f-45e9-42c1-a1bb-12a2f78f128e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_squad_batch(examples, question_column: str, context_column: str, answer_column: str):\n",
        "  questions = examples[question_column]\n",
        "  contexts = examples[context_column]\n",
        "  answers = examples[answer_column]\n",
        "  def generate_input(_question, _context):\n",
        "    return \" \".join([\"question:\", _question.lstrip(), \"context:\", _context.lstrip()])\n",
        "  inputs = [generate_input(question, context) for question, context in zip(questions, contexts)]\n",
        "  targets = [answer[\"text\"][0] if len(answer[\"text\"]) > 0 else \"\" for answer in answers]\n",
        "  return inputs, targets\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  inputs, targets = preprocess_squad_batch(examples, question_column, context_column, answer_column)\n",
        "\n",
        "  model_inputs = tokenizer(inputs, max_length=max_seq_length, padding=padding, truncation=True)\n",
        "  # Tokenize targets with text_target=...\n",
        "  labels = tokenizer(text_target=targets, max_length=max_answer_length, padding=padding, truncation=True)\n",
        "\n",
        "  # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
        "  # padding in the loss.\n",
        "  if padding == \"max_length\":\n",
        "    labels[\"input_ids\"] = [[(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]]\n",
        "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "  return model_inputs\n",
        "\n",
        "def preprocess_validation_function(examples):\n",
        "  inputs, targets = preprocess_squad_batch(examples, question_column, context_column, answer_column)\n",
        "  model_inputs = tokenizer(inputs, max_length=max_seq_length, padding=padding, truncation=True,\n",
        "                           return_overflowing_tokens=True,return_offsets_mapping=True)\n",
        "  # Tokenize targets with the `text_target` keyword argument\n",
        "  labels = tokenizer(text_target=targets, max_length=max_answer_length, padding=padding, truncation=True)\n",
        "\n",
        "  # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
        "  # padding in the loss.\n",
        "  if padding == \"max_length\":\n",
        "      labels[\"input_ids\"] = [\n",
        "          [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
        "      ]\n",
        "\n",
        "  # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "  # its corresponding example. This key gives us just that.\n",
        "  sample_mapping = model_inputs.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "  # For evaluation, we will need to convert our predictions to substrings of the context, so we keep the\n",
        "  # corresponding example_id and we will store the offset mappings.\n",
        "  model_inputs[\"example_id\"] = []\n",
        "  # Augment the overflowing tokens to the labels\n",
        "  labels_out = []\n",
        "\n",
        "  for i in range(len(model_inputs[\"input_ids\"])):\n",
        "      # One example can give several spans, this is the index of the example containing this span of text.\n",
        "      sample_index = sample_mapping[i]\n",
        "      model_inputs[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "      labels_out.append(labels[\"input_ids\"][sample_index])\n",
        "\n",
        "  model_inputs[\"labels\"] = labels_out\n",
        "  return model_inputs"
      ],
      "metadata": {
        "id": "P_tYDZTeiPPr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(preprocess_function, batched=True,\n",
        "                                  remove_columns=column_names, desc=\"Running tokenizer on train dataset\")"
      ],
      "metadata": {
        "id": "Fbad18mtk4lR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = eval_examples.map(preprocess_validation_function, batched=True,\n",
        "                                 remove_columns=column_names, desc=\"Running tokenizer on validation dataset\",)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "55b1fdf647b54833878d910b370d9f9e",
            "388aa4ee5f22457d907cf4c36579367c",
            "dc26ddd3bf7a400d9715ce775ff94aa7",
            "62353381932846539dfc03938eb632c1",
            "38b2aaf382314f3cb3eed1650b5e966e",
            "d25f5bbc68de472a83e19b2c598784ef",
            "dca9db7f839e43b78601be5e3ef72df9",
            "e742193a9d45401997f9562bb68b04d7",
            "3b32264bd0df4ad38a6f53029cd53422",
            "d4694f0fa5d14d1c80caacf5dabd3cf5",
            "a9490a8d8cc64dd4a25a0a7b4ba0e3be"
          ]
        },
        "id": "JWUrRXCKmvqj",
        "outputId": "431083b9-8870-4b61-a8c0-e9b945c407d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on validation dataset:   0%|          | 0/11873 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55b1fdf647b54833878d910b370d9f9e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v692UzDHi1mx",
        "outputId": "417a5bef-aa2b-4da4-d81b-dd28e2115701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shared.weight\n",
            "encoder.block.0.layer.0.SelfAttention.q.weight\n",
            "encoder.block.0.layer.0.SelfAttention.k.weight\n",
            "encoder.block.0.layer.0.SelfAttention.v.weight\n",
            "encoder.block.0.layer.0.SelfAttention.o.weight\n",
            "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight\n",
            "encoder.block.0.layer.0.layer_norm.weight\n",
            "encoder.block.0.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.0.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.0.layer.1.layer_norm.weight\n",
            "encoder.block.1.layer.0.SelfAttention.q.weight\n",
            "encoder.block.1.layer.0.SelfAttention.k.weight\n",
            "encoder.block.1.layer.0.SelfAttention.v.weight\n",
            "encoder.block.1.layer.0.SelfAttention.o.weight\n",
            "encoder.block.1.layer.0.layer_norm.weight\n",
            "encoder.block.1.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.1.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.1.layer.1.layer_norm.weight\n",
            "encoder.block.2.layer.0.SelfAttention.q.weight\n",
            "encoder.block.2.layer.0.SelfAttention.k.weight\n",
            "encoder.block.2.layer.0.SelfAttention.v.weight\n",
            "encoder.block.2.layer.0.SelfAttention.o.weight\n",
            "encoder.block.2.layer.0.layer_norm.weight\n",
            "encoder.block.2.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.2.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.2.layer.1.layer_norm.weight\n",
            "encoder.block.3.layer.0.SelfAttention.q.weight\n",
            "encoder.block.3.layer.0.SelfAttention.k.weight\n",
            "encoder.block.3.layer.0.SelfAttention.v.weight\n",
            "encoder.block.3.layer.0.SelfAttention.o.weight\n",
            "encoder.block.3.layer.0.layer_norm.weight\n",
            "encoder.block.3.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.3.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.3.layer.1.layer_norm.weight\n",
            "encoder.block.4.layer.0.SelfAttention.q.weight\n",
            "encoder.block.4.layer.0.SelfAttention.k.weight\n",
            "encoder.block.4.layer.0.SelfAttention.v.weight\n",
            "encoder.block.4.layer.0.SelfAttention.o.weight\n",
            "encoder.block.4.layer.0.layer_norm.weight\n",
            "encoder.block.4.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.4.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.4.layer.1.layer_norm.weight\n",
            "encoder.block.5.layer.0.SelfAttention.q.weight\n",
            "encoder.block.5.layer.0.SelfAttention.k.weight\n",
            "encoder.block.5.layer.0.SelfAttention.v.weight\n",
            "encoder.block.5.layer.0.SelfAttention.o.weight\n",
            "encoder.block.5.layer.0.layer_norm.weight\n",
            "encoder.block.5.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.5.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.5.layer.1.layer_norm.weight\n",
            "encoder.block.6.layer.0.SelfAttention.q.weight\n",
            "encoder.block.6.layer.0.SelfAttention.k.weight\n",
            "encoder.block.6.layer.0.SelfAttention.v.weight\n",
            "encoder.block.6.layer.0.SelfAttention.o.weight\n",
            "encoder.block.6.layer.0.layer_norm.weight\n",
            "encoder.block.6.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.6.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.6.layer.1.layer_norm.weight\n",
            "encoder.block.7.layer.0.SelfAttention.q.weight\n",
            "encoder.block.7.layer.0.SelfAttention.k.weight\n",
            "encoder.block.7.layer.0.SelfAttention.v.weight\n",
            "encoder.block.7.layer.0.SelfAttention.o.weight\n",
            "encoder.block.7.layer.0.layer_norm.weight\n",
            "encoder.block.7.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.7.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.7.layer.1.layer_norm.weight\n",
            "encoder.block.8.layer.0.SelfAttention.q.weight\n",
            "encoder.block.8.layer.0.SelfAttention.k.weight\n",
            "encoder.block.8.layer.0.SelfAttention.v.weight\n",
            "encoder.block.8.layer.0.SelfAttention.o.weight\n",
            "encoder.block.8.layer.0.layer_norm.weight\n",
            "encoder.block.8.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.8.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.8.layer.1.layer_norm.weight\n",
            "encoder.block.9.layer.0.SelfAttention.q.weight\n",
            "encoder.block.9.layer.0.SelfAttention.k.weight\n",
            "encoder.block.9.layer.0.SelfAttention.v.weight\n",
            "encoder.block.9.layer.0.SelfAttention.o.weight\n",
            "encoder.block.9.layer.0.layer_norm.weight\n",
            "encoder.block.9.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.9.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.9.layer.1.layer_norm.weight\n",
            "encoder.block.10.layer.0.SelfAttention.q.weight\n",
            "encoder.block.10.layer.0.SelfAttention.k.weight\n",
            "encoder.block.10.layer.0.SelfAttention.v.weight\n",
            "encoder.block.10.layer.0.SelfAttention.o.weight\n",
            "encoder.block.10.layer.0.layer_norm.weight\n",
            "encoder.block.10.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.10.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.10.layer.1.layer_norm.weight\n",
            "encoder.block.11.layer.0.SelfAttention.q.weight\n",
            "encoder.block.11.layer.0.SelfAttention.k.weight\n",
            "encoder.block.11.layer.0.SelfAttention.v.weight\n",
            "encoder.block.11.layer.0.SelfAttention.o.weight\n",
            "encoder.block.11.layer.0.layer_norm.weight\n",
            "encoder.block.11.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.11.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.11.layer.1.layer_norm.weight\n",
            "encoder.block.12.layer.0.SelfAttention.q.weight\n",
            "encoder.block.12.layer.0.SelfAttention.k.weight\n",
            "encoder.block.12.layer.0.SelfAttention.v.weight\n",
            "encoder.block.12.layer.0.SelfAttention.o.weight\n",
            "encoder.block.12.layer.0.layer_norm.weight\n",
            "encoder.block.12.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.12.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.12.layer.1.layer_norm.weight\n",
            "encoder.block.13.layer.0.SelfAttention.q.weight\n",
            "encoder.block.13.layer.0.SelfAttention.k.weight\n",
            "encoder.block.13.layer.0.SelfAttention.v.weight\n",
            "encoder.block.13.layer.0.SelfAttention.o.weight\n",
            "encoder.block.13.layer.0.layer_norm.weight\n",
            "encoder.block.13.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.13.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.13.layer.1.layer_norm.weight\n",
            "encoder.block.14.layer.0.SelfAttention.q.weight\n",
            "encoder.block.14.layer.0.SelfAttention.k.weight\n",
            "encoder.block.14.layer.0.SelfAttention.v.weight\n",
            "encoder.block.14.layer.0.SelfAttention.o.weight\n",
            "encoder.block.14.layer.0.layer_norm.weight\n",
            "encoder.block.14.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.14.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.14.layer.1.layer_norm.weight\n",
            "encoder.block.15.layer.0.SelfAttention.q.weight\n",
            "encoder.block.15.layer.0.SelfAttention.k.weight\n",
            "encoder.block.15.layer.0.SelfAttention.v.weight\n",
            "encoder.block.15.layer.0.SelfAttention.o.weight\n",
            "encoder.block.15.layer.0.layer_norm.weight\n",
            "encoder.block.15.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.15.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.15.layer.1.layer_norm.weight\n",
            "encoder.block.16.layer.0.SelfAttention.q.weight\n",
            "encoder.block.16.layer.0.SelfAttention.k.weight\n",
            "encoder.block.16.layer.0.SelfAttention.v.weight\n",
            "encoder.block.16.layer.0.SelfAttention.o.weight\n",
            "encoder.block.16.layer.0.layer_norm.weight\n",
            "encoder.block.16.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.16.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.16.layer.1.layer_norm.weight\n",
            "encoder.block.17.layer.0.SelfAttention.q.weight\n",
            "encoder.block.17.layer.0.SelfAttention.k.weight\n",
            "encoder.block.17.layer.0.SelfAttention.v.weight\n",
            "encoder.block.17.layer.0.SelfAttention.o.weight\n",
            "encoder.block.17.layer.0.layer_norm.weight\n",
            "encoder.block.17.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.17.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.17.layer.1.layer_norm.weight\n",
            "encoder.block.18.layer.0.SelfAttention.q.weight\n",
            "encoder.block.18.layer.0.SelfAttention.k.weight\n",
            "encoder.block.18.layer.0.SelfAttention.v.weight\n",
            "encoder.block.18.layer.0.SelfAttention.o.weight\n",
            "encoder.block.18.layer.0.layer_norm.weight\n",
            "encoder.block.18.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.18.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.18.layer.1.layer_norm.weight\n",
            "encoder.block.19.layer.0.SelfAttention.q.weight\n",
            "encoder.block.19.layer.0.SelfAttention.k.weight\n",
            "encoder.block.19.layer.0.SelfAttention.v.weight\n",
            "encoder.block.19.layer.0.SelfAttention.o.weight\n",
            "encoder.block.19.layer.0.layer_norm.weight\n",
            "encoder.block.19.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.19.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.19.layer.1.layer_norm.weight\n",
            "encoder.block.20.layer.0.SelfAttention.q.weight\n",
            "encoder.block.20.layer.0.SelfAttention.k.weight\n",
            "encoder.block.20.layer.0.SelfAttention.v.weight\n",
            "encoder.block.20.layer.0.SelfAttention.o.weight\n",
            "encoder.block.20.layer.0.layer_norm.weight\n",
            "encoder.block.20.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.20.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.20.layer.1.layer_norm.weight\n",
            "encoder.block.21.layer.0.SelfAttention.q.weight\n",
            "encoder.block.21.layer.0.SelfAttention.k.weight\n",
            "encoder.block.21.layer.0.SelfAttention.v.weight\n",
            "encoder.block.21.layer.0.SelfAttention.o.weight\n",
            "encoder.block.21.layer.0.layer_norm.weight\n",
            "encoder.block.21.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.21.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.21.layer.1.layer_norm.weight\n",
            "encoder.block.22.layer.0.SelfAttention.q.weight\n",
            "encoder.block.22.layer.0.SelfAttention.k.weight\n",
            "encoder.block.22.layer.0.SelfAttention.v.weight\n",
            "encoder.block.22.layer.0.SelfAttention.o.weight\n",
            "encoder.block.22.layer.0.layer_norm.weight\n",
            "encoder.block.22.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.22.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.22.layer.1.layer_norm.weight\n",
            "encoder.block.23.layer.0.SelfAttention.q.weight\n",
            "encoder.block.23.layer.0.SelfAttention.k.weight\n",
            "encoder.block.23.layer.0.SelfAttention.v.weight\n",
            "encoder.block.23.layer.0.SelfAttention.o.weight\n",
            "encoder.block.23.layer.0.layer_norm.weight\n",
            "encoder.block.23.layer.1.DenseReluDense.wi.weight\n",
            "encoder.block.23.layer.1.DenseReluDense.wo.weight\n",
            "encoder.block.23.layer.1.layer_norm.weight\n",
            "encoder.final_layer_norm.weight\n",
            "decoder.block.0.layer.0.SelfAttention.q.weight\n",
            "decoder.block.0.layer.0.SelfAttention.k.weight\n",
            "decoder.block.0.layer.0.SelfAttention.v.weight\n",
            "decoder.block.0.layer.0.SelfAttention.o.weight\n",
            "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight\n",
            "decoder.block.0.layer.0.layer_norm.weight\n",
            "decoder.block.0.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.0.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.0.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.0.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.0.layer.1.layer_norm.weight\n",
            "decoder.block.0.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.0.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.0.layer.2.layer_norm.weight\n",
            "decoder.block.1.layer.0.SelfAttention.q.weight\n",
            "decoder.block.1.layer.0.SelfAttention.k.weight\n",
            "decoder.block.1.layer.0.SelfAttention.v.weight\n",
            "decoder.block.1.layer.0.SelfAttention.o.weight\n",
            "decoder.block.1.layer.0.layer_norm.weight\n",
            "decoder.block.1.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.1.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.1.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.1.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.1.layer.1.layer_norm.weight\n",
            "decoder.block.1.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.1.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.1.layer.2.layer_norm.weight\n",
            "decoder.block.2.layer.0.SelfAttention.q.weight\n",
            "decoder.block.2.layer.0.SelfAttention.k.weight\n",
            "decoder.block.2.layer.0.SelfAttention.v.weight\n",
            "decoder.block.2.layer.0.SelfAttention.o.weight\n",
            "decoder.block.2.layer.0.layer_norm.weight\n",
            "decoder.block.2.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.2.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.2.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.2.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.2.layer.1.layer_norm.weight\n",
            "decoder.block.2.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.2.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.2.layer.2.layer_norm.weight\n",
            "decoder.block.3.layer.0.SelfAttention.q.weight\n",
            "decoder.block.3.layer.0.SelfAttention.k.weight\n",
            "decoder.block.3.layer.0.SelfAttention.v.weight\n",
            "decoder.block.3.layer.0.SelfAttention.o.weight\n",
            "decoder.block.3.layer.0.layer_norm.weight\n",
            "decoder.block.3.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.3.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.3.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.3.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.3.layer.1.layer_norm.weight\n",
            "decoder.block.3.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.3.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.3.layer.2.layer_norm.weight\n",
            "decoder.block.4.layer.0.SelfAttention.q.weight\n",
            "decoder.block.4.layer.0.SelfAttention.k.weight\n",
            "decoder.block.4.layer.0.SelfAttention.v.weight\n",
            "decoder.block.4.layer.0.SelfAttention.o.weight\n",
            "decoder.block.4.layer.0.layer_norm.weight\n",
            "decoder.block.4.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.4.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.4.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.4.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.4.layer.1.layer_norm.weight\n",
            "decoder.block.4.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.4.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.4.layer.2.layer_norm.weight\n",
            "decoder.block.5.layer.0.SelfAttention.q.weight\n",
            "decoder.block.5.layer.0.SelfAttention.k.weight\n",
            "decoder.block.5.layer.0.SelfAttention.v.weight\n",
            "decoder.block.5.layer.0.SelfAttention.o.weight\n",
            "decoder.block.5.layer.0.layer_norm.weight\n",
            "decoder.block.5.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.5.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.5.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.5.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.5.layer.1.layer_norm.weight\n",
            "decoder.block.5.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.5.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.5.layer.2.layer_norm.weight\n",
            "decoder.block.6.layer.0.SelfAttention.q.weight\n",
            "decoder.block.6.layer.0.SelfAttention.k.weight\n",
            "decoder.block.6.layer.0.SelfAttention.v.weight\n",
            "decoder.block.6.layer.0.SelfAttention.o.weight\n",
            "decoder.block.6.layer.0.layer_norm.weight\n",
            "decoder.block.6.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.6.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.6.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.6.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.6.layer.1.layer_norm.weight\n",
            "decoder.block.6.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.6.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.6.layer.2.layer_norm.weight\n",
            "decoder.block.7.layer.0.SelfAttention.q.weight\n",
            "decoder.block.7.layer.0.SelfAttention.k.weight\n",
            "decoder.block.7.layer.0.SelfAttention.v.weight\n",
            "decoder.block.7.layer.0.SelfAttention.o.weight\n",
            "decoder.block.7.layer.0.layer_norm.weight\n",
            "decoder.block.7.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.7.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.7.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.7.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.7.layer.1.layer_norm.weight\n",
            "decoder.block.7.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.7.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.7.layer.2.layer_norm.weight\n",
            "decoder.block.8.layer.0.SelfAttention.q.weight\n",
            "decoder.block.8.layer.0.SelfAttention.k.weight\n",
            "decoder.block.8.layer.0.SelfAttention.v.weight\n",
            "decoder.block.8.layer.0.SelfAttention.o.weight\n",
            "decoder.block.8.layer.0.layer_norm.weight\n",
            "decoder.block.8.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.8.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.8.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.8.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.8.layer.1.layer_norm.weight\n",
            "decoder.block.8.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.8.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.8.layer.2.layer_norm.weight\n",
            "decoder.block.9.layer.0.SelfAttention.q.weight\n",
            "decoder.block.9.layer.0.SelfAttention.k.weight\n",
            "decoder.block.9.layer.0.SelfAttention.v.weight\n",
            "decoder.block.9.layer.0.SelfAttention.o.weight\n",
            "decoder.block.9.layer.0.layer_norm.weight\n",
            "decoder.block.9.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.9.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.9.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.9.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.9.layer.1.layer_norm.weight\n",
            "decoder.block.9.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.9.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.9.layer.2.layer_norm.weight\n",
            "decoder.block.10.layer.0.SelfAttention.q.weight\n",
            "decoder.block.10.layer.0.SelfAttention.k.weight\n",
            "decoder.block.10.layer.0.SelfAttention.v.weight\n",
            "decoder.block.10.layer.0.SelfAttention.o.weight\n",
            "decoder.block.10.layer.0.layer_norm.weight\n",
            "decoder.block.10.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.10.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.10.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.10.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.10.layer.1.layer_norm.weight\n",
            "decoder.block.10.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.10.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.10.layer.2.layer_norm.weight\n",
            "decoder.block.11.layer.0.SelfAttention.q.weight\n",
            "decoder.block.11.layer.0.SelfAttention.k.weight\n",
            "decoder.block.11.layer.0.SelfAttention.v.weight\n",
            "decoder.block.11.layer.0.SelfAttention.o.weight\n",
            "decoder.block.11.layer.0.layer_norm.weight\n",
            "decoder.block.11.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.11.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.11.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.11.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.11.layer.1.layer_norm.weight\n",
            "decoder.block.11.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.11.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.11.layer.2.layer_norm.weight\n",
            "decoder.block.12.layer.0.SelfAttention.q.weight\n",
            "decoder.block.12.layer.0.SelfAttention.k.weight\n",
            "decoder.block.12.layer.0.SelfAttention.v.weight\n",
            "decoder.block.12.layer.0.SelfAttention.o.weight\n",
            "decoder.block.12.layer.0.layer_norm.weight\n",
            "decoder.block.12.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.12.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.12.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.12.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.12.layer.1.layer_norm.weight\n",
            "decoder.block.12.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.12.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.12.layer.2.layer_norm.weight\n",
            "decoder.block.13.layer.0.SelfAttention.q.weight\n",
            "decoder.block.13.layer.0.SelfAttention.k.weight\n",
            "decoder.block.13.layer.0.SelfAttention.v.weight\n",
            "decoder.block.13.layer.0.SelfAttention.o.weight\n",
            "decoder.block.13.layer.0.layer_norm.weight\n",
            "decoder.block.13.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.13.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.13.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.13.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.13.layer.1.layer_norm.weight\n",
            "decoder.block.13.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.13.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.13.layer.2.layer_norm.weight\n",
            "decoder.block.14.layer.0.SelfAttention.q.weight\n",
            "decoder.block.14.layer.0.SelfAttention.k.weight\n",
            "decoder.block.14.layer.0.SelfAttention.v.weight\n",
            "decoder.block.14.layer.0.SelfAttention.o.weight\n",
            "decoder.block.14.layer.0.layer_norm.weight\n",
            "decoder.block.14.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.14.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.14.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.14.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.14.layer.1.layer_norm.weight\n",
            "decoder.block.14.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.14.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.14.layer.2.layer_norm.weight\n",
            "decoder.block.15.layer.0.SelfAttention.q.weight\n",
            "decoder.block.15.layer.0.SelfAttention.k.weight\n",
            "decoder.block.15.layer.0.SelfAttention.v.weight\n",
            "decoder.block.15.layer.0.SelfAttention.o.weight\n",
            "decoder.block.15.layer.0.layer_norm.weight\n",
            "decoder.block.15.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.15.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.15.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.15.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.15.layer.1.layer_norm.weight\n",
            "decoder.block.15.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.15.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.15.layer.2.layer_norm.weight\n",
            "decoder.block.16.layer.0.SelfAttention.q.weight\n",
            "decoder.block.16.layer.0.SelfAttention.k.weight\n",
            "decoder.block.16.layer.0.SelfAttention.v.weight\n",
            "decoder.block.16.layer.0.SelfAttention.o.weight\n",
            "decoder.block.16.layer.0.layer_norm.weight\n",
            "decoder.block.16.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.16.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.16.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.16.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.16.layer.1.layer_norm.weight\n",
            "decoder.block.16.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.16.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.16.layer.2.layer_norm.weight\n",
            "decoder.block.17.layer.0.SelfAttention.q.weight\n",
            "decoder.block.17.layer.0.SelfAttention.k.weight\n",
            "decoder.block.17.layer.0.SelfAttention.v.weight\n",
            "decoder.block.17.layer.0.SelfAttention.o.weight\n",
            "decoder.block.17.layer.0.layer_norm.weight\n",
            "decoder.block.17.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.17.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.17.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.17.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.17.layer.1.layer_norm.weight\n",
            "decoder.block.17.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.17.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.17.layer.2.layer_norm.weight\n",
            "decoder.block.18.layer.0.SelfAttention.q.weight\n",
            "decoder.block.18.layer.0.SelfAttention.k.weight\n",
            "decoder.block.18.layer.0.SelfAttention.v.weight\n",
            "decoder.block.18.layer.0.SelfAttention.o.weight\n",
            "decoder.block.18.layer.0.layer_norm.weight\n",
            "decoder.block.18.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.18.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.18.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.18.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.18.layer.1.layer_norm.weight\n",
            "decoder.block.18.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.18.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.18.layer.2.layer_norm.weight\n",
            "decoder.block.19.layer.0.SelfAttention.q.weight\n",
            "decoder.block.19.layer.0.SelfAttention.k.weight\n",
            "decoder.block.19.layer.0.SelfAttention.v.weight\n",
            "decoder.block.19.layer.0.SelfAttention.o.weight\n",
            "decoder.block.19.layer.0.layer_norm.weight\n",
            "decoder.block.19.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.19.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.19.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.19.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.19.layer.1.layer_norm.weight\n",
            "decoder.block.19.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.19.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.19.layer.2.layer_norm.weight\n",
            "decoder.block.20.layer.0.SelfAttention.q.weight\n",
            "decoder.block.20.layer.0.SelfAttention.k.weight\n",
            "decoder.block.20.layer.0.SelfAttention.v.weight\n",
            "decoder.block.20.layer.0.SelfAttention.o.weight\n",
            "decoder.block.20.layer.0.layer_norm.weight\n",
            "decoder.block.20.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.20.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.20.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.20.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.20.layer.1.layer_norm.weight\n",
            "decoder.block.20.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.20.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.20.layer.2.layer_norm.weight\n",
            "decoder.block.21.layer.0.SelfAttention.q.weight\n",
            "decoder.block.21.layer.0.SelfAttention.k.weight\n",
            "decoder.block.21.layer.0.SelfAttention.v.weight\n",
            "decoder.block.21.layer.0.SelfAttention.o.weight\n",
            "decoder.block.21.layer.0.layer_norm.weight\n",
            "decoder.block.21.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.21.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.21.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.21.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.21.layer.1.layer_norm.weight\n",
            "decoder.block.21.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.21.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.21.layer.2.layer_norm.weight\n",
            "decoder.block.22.layer.0.SelfAttention.q.weight\n",
            "decoder.block.22.layer.0.SelfAttention.k.weight\n",
            "decoder.block.22.layer.0.SelfAttention.v.weight\n",
            "decoder.block.22.layer.0.SelfAttention.o.weight\n",
            "decoder.block.22.layer.0.layer_norm.weight\n",
            "decoder.block.22.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.22.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.22.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.22.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.22.layer.1.layer_norm.weight\n",
            "decoder.block.22.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.22.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.22.layer.2.layer_norm.weight\n",
            "decoder.block.23.layer.0.SelfAttention.q.weight\n",
            "decoder.block.23.layer.0.SelfAttention.k.weight\n",
            "decoder.block.23.layer.0.SelfAttention.v.weight\n",
            "decoder.block.23.layer.0.SelfAttention.o.weight\n",
            "decoder.block.23.layer.0.layer_norm.weight\n",
            "decoder.block.23.layer.1.EncDecAttention.q.weight\n",
            "decoder.block.23.layer.1.EncDecAttention.k.weight\n",
            "decoder.block.23.layer.1.EncDecAttention.v.weight\n",
            "decoder.block.23.layer.1.EncDecAttention.o.weight\n",
            "decoder.block.23.layer.1.layer_norm.weight\n",
            "decoder.block.23.layer.2.DenseReluDense.wi.weight\n",
            "decoder.block.23.layer.2.DenseReluDense.wo.weight\n",
            "decoder.block.23.layer.2.layer_norm.weight\n",
            "decoder.final_layer_norm.weight\n"
          ]
        }
      ],
      "source": [
        " for name, p in model.named_parameters():\n",
        "   if p.requires_grad == True:\n",
        "     print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GPNHacLO-9x",
        "outputId": "0d658e16-3a4b-4a77-f70e-f7ec2f39c25f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "737668096"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "new_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "new_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rPIPqMQoeL9d"
      },
      "outputs": [],
      "source": [
        "from transformers.adapters.configuration import ParallelConfig\n",
        "\n",
        "adapter_non_linearity = 'relu'\n",
        "adapter_reduction_factor = 64\n",
        "leave_out = []\n",
        "task_name = \"squad2\"\n",
        "adapter_config = ParallelConfig(scaling=\"learned\", non_linearity=adapter_non_linearity,\n",
        "                                reduction_factor=adapter_reduction_factor,)\n",
        "model.add_adapter(task_name, config=adapter_config)\n",
        "model.set_active_adapters(task_name)\n",
        "model.train_adapter([task_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt9bkfHCi1sm",
        "outputId": "6bce5540-19c1-42b9-ed34-e5a2eda929bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder.block.0.layer.1.adapters.squad2.scaling\n",
            "encoder.block.0.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.0.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.0.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.0.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.1.layer.1.adapters.squad2.scaling\n",
            "encoder.block.1.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.1.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.1.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.1.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.2.layer.1.adapters.squad2.scaling\n",
            "encoder.block.2.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.2.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.2.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.2.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.3.layer.1.adapters.squad2.scaling\n",
            "encoder.block.3.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.3.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.3.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.3.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.4.layer.1.adapters.squad2.scaling\n",
            "encoder.block.4.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.4.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.4.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.4.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.5.layer.1.adapters.squad2.scaling\n",
            "encoder.block.5.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.5.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.5.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.5.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.6.layer.1.adapters.squad2.scaling\n",
            "encoder.block.6.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.6.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.6.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.6.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.7.layer.1.adapters.squad2.scaling\n",
            "encoder.block.7.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.7.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.7.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.7.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.8.layer.1.adapters.squad2.scaling\n",
            "encoder.block.8.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.8.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.8.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.8.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.9.layer.1.adapters.squad2.scaling\n",
            "encoder.block.9.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.9.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.9.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.9.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.10.layer.1.adapters.squad2.scaling\n",
            "encoder.block.10.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.10.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.10.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.10.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.11.layer.1.adapters.squad2.scaling\n",
            "encoder.block.11.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.11.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.11.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.11.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.12.layer.1.adapters.squad2.scaling\n",
            "encoder.block.12.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.12.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.12.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.12.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.13.layer.1.adapters.squad2.scaling\n",
            "encoder.block.13.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.13.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.13.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.13.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.14.layer.1.adapters.squad2.scaling\n",
            "encoder.block.14.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.14.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.14.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.14.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.15.layer.1.adapters.squad2.scaling\n",
            "encoder.block.15.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.15.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.15.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.15.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.16.layer.1.adapters.squad2.scaling\n",
            "encoder.block.16.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.16.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.16.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.16.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.17.layer.1.adapters.squad2.scaling\n",
            "encoder.block.17.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.17.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.17.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.17.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.18.layer.1.adapters.squad2.scaling\n",
            "encoder.block.18.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.18.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.18.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.18.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.19.layer.1.adapters.squad2.scaling\n",
            "encoder.block.19.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.19.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.19.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.19.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.20.layer.1.adapters.squad2.scaling\n",
            "encoder.block.20.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.20.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.20.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.20.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.21.layer.1.adapters.squad2.scaling\n",
            "encoder.block.21.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.21.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.21.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.21.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.22.layer.1.adapters.squad2.scaling\n",
            "encoder.block.22.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.22.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.22.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.22.layer.1.adapters.squad2.adapter_up.bias\n",
            "encoder.block.23.layer.1.adapters.squad2.scaling\n",
            "encoder.block.23.layer.1.adapters.squad2.adapter_down.0.weight\n",
            "encoder.block.23.layer.1.adapters.squad2.adapter_down.0.bias\n",
            "encoder.block.23.layer.1.adapters.squad2.adapter_up.weight\n",
            "encoder.block.23.layer.1.adapters.squad2.adapter_up.bias\n",
            "decoder.block.0.layer.2.adapters.squad2.scaling\n",
            "decoder.block.0.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.0.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.0.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.0.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.1.layer.2.adapters.squad2.scaling\n",
            "decoder.block.1.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.1.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.1.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.1.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.2.layer.2.adapters.squad2.scaling\n",
            "decoder.block.2.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.2.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.2.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.2.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.3.layer.2.adapters.squad2.scaling\n",
            "decoder.block.3.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.3.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.3.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.3.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.4.layer.2.adapters.squad2.scaling\n",
            "decoder.block.4.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.4.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.4.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.4.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.5.layer.2.adapters.squad2.scaling\n",
            "decoder.block.5.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.5.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.5.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.5.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.6.layer.2.adapters.squad2.scaling\n",
            "decoder.block.6.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.6.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.6.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.6.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.7.layer.2.adapters.squad2.scaling\n",
            "decoder.block.7.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.7.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.7.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.7.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.8.layer.2.adapters.squad2.scaling\n",
            "decoder.block.8.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.8.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.8.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.8.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.9.layer.2.adapters.squad2.scaling\n",
            "decoder.block.9.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.9.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.9.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.9.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.10.layer.2.adapters.squad2.scaling\n",
            "decoder.block.10.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.10.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.10.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.10.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.11.layer.2.adapters.squad2.scaling\n",
            "decoder.block.11.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.11.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.11.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.11.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.12.layer.2.adapters.squad2.scaling\n",
            "decoder.block.12.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.12.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.12.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.12.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.13.layer.2.adapters.squad2.scaling\n",
            "decoder.block.13.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.13.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.13.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.13.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.14.layer.2.adapters.squad2.scaling\n",
            "decoder.block.14.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.14.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.14.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.14.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.15.layer.2.adapters.squad2.scaling\n",
            "decoder.block.15.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.15.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.15.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.15.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.16.layer.2.adapters.squad2.scaling\n",
            "decoder.block.16.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.16.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.16.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.16.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.17.layer.2.adapters.squad2.scaling\n",
            "decoder.block.17.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.17.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.17.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.17.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.18.layer.2.adapters.squad2.scaling\n",
            "decoder.block.18.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.18.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.18.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.18.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.19.layer.2.adapters.squad2.scaling\n",
            "decoder.block.19.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.19.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.19.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.19.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.20.layer.2.adapters.squad2.scaling\n",
            "decoder.block.20.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.20.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.20.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.20.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.21.layer.2.adapters.squad2.scaling\n",
            "decoder.block.21.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.21.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.21.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.21.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.22.layer.2.adapters.squad2.scaling\n",
            "decoder.block.22.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.22.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.22.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.22.layer.2.adapters.squad2.adapter_up.bias\n",
            "decoder.block.23.layer.2.adapters.squad2.scaling\n",
            "decoder.block.23.layer.2.adapters.squad2.adapter_down.0.weight\n",
            "decoder.block.23.layer.2.adapters.squad2.adapter_down.0.bias\n",
            "decoder.block.23.layer.2.adapters.squad2.adapter_up.weight\n",
            "decoder.block.23.layer.2.adapters.squad2.adapter_up.bias\n"
          ]
        }
      ],
      "source": [
        "for name, p in model.named_parameters():\n",
        "  if p.requires_grad == True:\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EydRPwBYMOfm",
        "outputId": "063dcccb-736e-444f-edc3-8a6d1090c318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1622832"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "new_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "new_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kzXI906Li1vm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        overwrite_output_dir=overwrite_output_dir,\n",
        "        do_train=do_train,\n",
        "        do_eval=do_eval,\n",
        "        evaluation_strategy=evaluation_strategy,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        adam_beta1=adam_beta1,\n",
        "        adam_beta2=adam_beta2,\n",
        "        adam_epsilon=adam_epsilon,\n",
        "        #num_train_epochs=num_train_epochs,\n",
        "        max_steps=max_steps,\n",
        "        lr_scheduler_type=lr_scheduler_type,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        warmup_steps=warmup_steps,\n",
        "        logging_dir=logging_dir,         # directory for storing logs\n",
        "        logging_strategy=evaluation_strategy,\n",
        "        logging_steps=logging_steps,     # if strategy = \"steps\"\n",
        "        save_strategy=evaluation_strategy,          # model checkpoint saving strategy\n",
        "        save_steps=logging_steps,        # if strategy = \"steps\"\n",
        "        save_total_limit=save_total_limit,\n",
        "        fp16=fp16,\n",
        "        eval_steps=logging_steps,        # if strategy = \"steps\"\n",
        "        load_best_model_at_end=load_best_model_at_end,\n",
        "        metric_for_best_model=metric_for_best_model,\n",
        "        greater_is_better=greater_is_better\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDfs7ZXglKXc",
        "outputId": "bba8c5d2-7f1e-4f85-ed3f-68df5866646c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "from transformers import default_data_collator\n",
        "\n",
        "label_pad_token_id = -100\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=label_pad_token_id,\n",
        "                                       pad_to_multiple_of=8)\n",
        "train_adapter=True\n",
        "#do_save_full_model=train_adapter, # save full model as we finetuned head + embeddings\n",
        "trainer = AdapterTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "5_ms6goslKep",
        "outputId": "9e5b8f7a-e78c-4176-a61a-0049ce7fddb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 130319\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10\n",
            "  Number of trainable parameters = 1622832\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:05, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10, training_loss=0.0, metrics={'train_runtime': 6.9578, 'train_samples_per_second': 5.749, 'train_steps_per_second': 1.437, 'total_flos': 51538275102720.0, 'train_loss': 0.0, 'epoch': 0.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "0Bv8lYy_lK0S",
        "outputId": "c5e6b479-8c97-41b1-bced-9de3d0379691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 13095\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='376' max='3274' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 376/3274 01:37 < 12:35, 3.84 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1e206d3f7f26>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2903\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2904\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3034\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m                 \u001b[0mpreds_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_prediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    111\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    111\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         return type(tensors)(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Let's figure out the new shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.75 GiB (GPU 0; 14.75 GiB total capacity; 10.30 GiB already allocated; 1.74 GiB free; 12.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "raw_predictions = trainer.predict(eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R41YElukKjoO",
        "outputId": "1f0d10b8-ade7-4e2f-de37-fc1a2bc623fa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct  2 16:18:28 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    32W /  70W |  13323MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmPSSrjdlZ6k"
      },
      "outputs": [],
      "source": [
        "#validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "  return metric.compute(predictions=p.predictions, references=p.label_ids)\n",
        "\n",
        "# Post-processing:\n",
        "def post_processing_function(examples, features, outputs, stage=\"eval\"):\n",
        "  # Decode the predicted tokens.\n",
        "  preds = outputs.predictions\n",
        "  if isinstance(preds, tuple):\n",
        "      preds = preds[0]\n",
        "  decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "  # Build a map example to its corresponding features.\n",
        "  example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "  feature_per_example = {example_id_to_index[feature[\"example_id\"]]: i for i, feature in enumerate(features)}\n",
        "  predictions = {}\n",
        "  # Let's loop over all the examples!\n",
        "  for example_index, example in enumerate(examples):\n",
        "      # This is the index of the feature associated to the current example.\n",
        "      feature_index = feature_per_example[example_index]\n",
        "      predictions[example[\"id\"]] = decoded_preds[feature_index]\n",
        "\n",
        "  # Format the result to the format the metric expects.\n",
        "  formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in predictions.items()]\n",
        "  references = [{\"id\": ex[\"id\"], \"answers\": ex[answer_column]} for ex in examples]\n",
        "  return EvalPrediction(predictions=formatted_predictions, label_ids=references)"
      ],
      "metadata": {
        "id": "iemHn1iwD5yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "57e214c6c5c540b18ec86c99bee1a10e",
            "58c40dba4d03448aac14a70e55073ebc",
            "a4156e5305774fe9a8ff6121fc4fef65",
            "7a8e9ec1b36a4dd18d8938e354e0224d",
            "3fef105b0184469892ae373e69298935",
            "06b8be90b1c14026af86fe609b7ad799",
            "d55ecc441c15428c80094c40aa1d7173",
            "de06396baf154658a661a89c50be55a1",
            "326d05ce87934dab898394d987b198b2",
            "6689db4856674c879151ea3e99de9323",
            "87d7551f7e6249cbaebe2892e891e0f9"
          ]
        },
        "id": "hgpUGYW-laPr",
        "outputId": "30fd5f8b-0ac8-4079-b7b0-9b1550f1ac16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Post-processing 11873 example predictions split into 12711 features.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████| 11873/11873 [00:08<00:00, 1370.27it/s]\n"
          ]
        }
      ],
      "source": [
        "final_predictions = postprocess_qa_predictions(raw_datasets[\"validation\"], validation_features, raw_predictions.predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "472d829c4f2747e4b70de43c89a8a779",
            "baa0ba745c2c4ea7b59164865c0c438f",
            "d7bff0ad32fa4d63a67f7d71c6a8ba55",
            "ff504abb3c4f4d35a2198d906acf49e8",
            "6bd02c43b7164c469035ae6c31d7e8fb",
            "734f5006de024cdb8e28dfc5f6538eb2",
            "0eca645e34d7419ebaa0966c87eab01b",
            "b83925ef0fee4e4c8a6d663159b7d3c6",
            "afe41e33cce2435086b773ce5d860a80",
            "1f62598fb4a14ce385c92f241ba0ac6a",
            "8a1cec50d4604fd1bbae0ef1ee83d90c",
            "a1211e9fcecd4cd5bff22cd4accc4a76",
            "d464230067254bfea92c79aa67cc3639",
            "88cfac655d9c4977aa19af2097cd7d38",
            "b55e6e03cf9e4fc7b427084b90d4dca5",
            "02fbfda565dd4469b2af14eb6d4c0641",
            "5a6b3db1b9c14bec85f1ef4f7bf08de8",
            "348855cc3c7a45568e4a35e46e7db1d5",
            "9f5112d66d044e6088f9aa20f1b80aca",
            "7e61ffe801214d1eade8258add479bee",
            "2d3ef180a06f4465bdf846f788a8c3c5",
            "b1a1490737f7400b9c297b51b8caaf5b"
          ]
        },
        "id": "gUVqlMwIlaVg",
        "outputId": "69e68986-ccaa-4756-d506-0f695044d053"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5226/3461119883.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"squad_v2\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'exact': 83.17190263623347,\n",
              " 'f1': 86.18698935577652,\n",
              " 'total': 11873,\n",
              " 'HasAns_exact': 78.66059379217273,\n",
              " 'HasAns_f1': 84.69941373500916,\n",
              " 'HasAns_total': 5928,\n",
              " 'NoAns_exact': 87.67031118587047,\n",
              " 'NoAns_f1': 87.67031118587047,\n",
              " 'NoAns_total': 5945,\n",
              " 'best_exact': 83.17190263623347,\n",
              " 'best_exact_thresh': 0.0,\n",
              " 'best_f1': 86.18698935577635,\n",
              " 'best_f1_thresh': 0.0}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric = load_metric(\"squad_v2\")\n",
        "#formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
        "#references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in raw_datasets[\"validation\"]]\n",
        "compute_metrics(final_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzfz-N-zfLM6",
        "outputId": "296d1c49-3110-4878-c282-a341713c98fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in ./saved_model/adapter_config.json\n",
            "Module weights saved in ./saved_model/pytorch_adapter.bin\n",
            "Configuration saved in ./saved_model/head_config.json\n",
            "Module weights saved in ./saved_model/pytorch_model_head.bin\n"
          ]
        }
      ],
      "source": [
        "trainer.model.save_adapter(\"./saved_model\", adapter_name=\"squad\", with_head=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02fbfda565dd4469b2af14eb6d4c0641": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b8be90b1c14026af86fe609b7ad799": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eca645e34d7419ebaa0966c87eab01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f62598fb4a14ce385c92f241ba0ac6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3ef180a06f4465bdf846f788a8c3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "326d05ce87934dab898394d987b198b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "348855cc3c7a45568e4a35e46e7db1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fef105b0184469892ae373e69298935": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472d829c4f2747e4b70de43c89a8a779": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baa0ba745c2c4ea7b59164865c0c438f",
              "IPY_MODEL_d7bff0ad32fa4d63a67f7d71c6a8ba55",
              "IPY_MODEL_ff504abb3c4f4d35a2198d906acf49e8"
            ],
            "layout": "IPY_MODEL_6bd02c43b7164c469035ae6c31d7e8fb"
          }
        },
        "57e214c6c5c540b18ec86c99bee1a10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58c40dba4d03448aac14a70e55073ebc",
              "IPY_MODEL_a4156e5305774fe9a8ff6121fc4fef65",
              "IPY_MODEL_7a8e9ec1b36a4dd18d8938e354e0224d"
            ],
            "layout": "IPY_MODEL_3fef105b0184469892ae373e69298935"
          }
        },
        "58c40dba4d03448aac14a70e55073ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b8be90b1c14026af86fe609b7ad799",
            "placeholder": "​",
            "style": "IPY_MODEL_d55ecc441c15428c80094c40aa1d7173",
            "value": "100%"
          }
        },
        "5a6b3db1b9c14bec85f1ef4f7bf08de8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6689db4856674c879151ea3e99de9323": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bd02c43b7164c469035ae6c31d7e8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734f5006de024cdb8e28dfc5f6538eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8e9ec1b36a4dd18d8938e354e0224d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6689db4856674c879151ea3e99de9323",
            "placeholder": "​",
            "style": "IPY_MODEL_87d7551f7e6249cbaebe2892e891e0f9",
            "value": " 11873/11873 [00:38&lt;00:00, 441.76it/s]"
          }
        },
        "7e61ffe801214d1eade8258add479bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87d7551f7e6249cbaebe2892e891e0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88cfac655d9c4977aa19af2097cd7d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5112d66d044e6088f9aa20f1b80aca",
            "max": 3188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e61ffe801214d1eade8258add479bee",
            "value": 3188
          }
        },
        "8a1cec50d4604fd1bbae0ef1ee83d90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f5112d66d044e6088f9aa20f1b80aca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1211e9fcecd4cd5bff22cd4accc4a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d464230067254bfea92c79aa67cc3639",
              "IPY_MODEL_88cfac655d9c4977aa19af2097cd7d38",
              "IPY_MODEL_b55e6e03cf9e4fc7b427084b90d4dca5"
            ],
            "layout": "IPY_MODEL_02fbfda565dd4469b2af14eb6d4c0641"
          }
        },
        "a4156e5305774fe9a8ff6121fc4fef65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de06396baf154658a661a89c50be55a1",
            "max": 11873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_326d05ce87934dab898394d987b198b2",
            "value": 11873
          }
        },
        "afe41e33cce2435086b773ce5d860a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1a1490737f7400b9c297b51b8caaf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b55e6e03cf9e4fc7b427084b90d4dca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d3ef180a06f4465bdf846f788a8c3c5",
            "placeholder": "​",
            "style": "IPY_MODEL_b1a1490737f7400b9c297b51b8caaf5b",
            "value": " 11.3k/? [00:00&lt;00:00, 779kB/s]"
          }
        },
        "b83925ef0fee4e4c8a6d663159b7d3c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baa0ba745c2c4ea7b59164865c0c438f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_734f5006de024cdb8e28dfc5f6538eb2",
            "placeholder": "​",
            "style": "IPY_MODEL_0eca645e34d7419ebaa0966c87eab01b",
            "value": "Downloading builder script: "
          }
        },
        "d464230067254bfea92c79aa67cc3639": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a6b3db1b9c14bec85f1ef4f7bf08de8",
            "placeholder": "​",
            "style": "IPY_MODEL_348855cc3c7a45568e4a35e46e7db1d5",
            "value": "Downloading extra modules: "
          }
        },
        "d55ecc441c15428c80094c40aa1d7173": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7bff0ad32fa4d63a67f7d71c6a8ba55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b83925ef0fee4e4c8a6d663159b7d3c6",
            "max": 2253,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afe41e33cce2435086b773ce5d860a80",
            "value": 2253
          }
        },
        "de06396baf154658a661a89c50be55a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff504abb3c4f4d35a2198d906acf49e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f62598fb4a14ce385c92f241ba0ac6a",
            "placeholder": "​",
            "style": "IPY_MODEL_8a1cec50d4604fd1bbae0ef1ee83d90c",
            "value": " 6.46k/? [00:00&lt;00:00, 311kB/s]"
          }
        },
        "55b1fdf647b54833878d910b370d9f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_388aa4ee5f22457d907cf4c36579367c",
              "IPY_MODEL_dc26ddd3bf7a400d9715ce775ff94aa7",
              "IPY_MODEL_62353381932846539dfc03938eb632c1"
            ],
            "layout": "IPY_MODEL_38b2aaf382314f3cb3eed1650b5e966e"
          }
        },
        "388aa4ee5f22457d907cf4c36579367c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d25f5bbc68de472a83e19b2c598784ef",
            "placeholder": "​",
            "style": "IPY_MODEL_dca9db7f839e43b78601be5e3ef72df9",
            "value": "Running tokenizer on validation dataset: 100%"
          }
        },
        "dc26ddd3bf7a400d9715ce775ff94aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e742193a9d45401997f9562bb68b04d7",
            "max": 11873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b32264bd0df4ad38a6f53029cd53422",
            "value": 11873
          }
        },
        "62353381932846539dfc03938eb632c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4694f0fa5d14d1c80caacf5dabd3cf5",
            "placeholder": "​",
            "style": "IPY_MODEL_a9490a8d8cc64dd4a25a0a7b4ba0e3be",
            "value": " 11873/11873 [00:13&lt;00:00, 1007.62 examples/s]"
          }
        },
        "38b2aaf382314f3cb3eed1650b5e966e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25f5bbc68de472a83e19b2c598784ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca9db7f839e43b78601be5e3ef72df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e742193a9d45401997f9562bb68b04d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b32264bd0df4ad38a6f53029cd53422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4694f0fa5d14d1c80caacf5dabd3cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9490a8d8cc64dd4a25a0a7b4ba0e3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}